<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Efficient Sum and Mean · LossFunctions.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://JuliaML.github.io/LossFunctions.jl/user/aggregate/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/style.css" rel="stylesheet" type="text/css"/><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="LossFunctions.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">LossFunctions.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><span class="tocitem">Introduction</span><ul><li><a class="tocitem" href="../../introduction/gettingstarted/">Getting Started</a></li><li><a class="tocitem" href="../../introduction/motivation/">Background and Motivation</a></li></ul></li><li><span class="tocitem">User&#39;s Guide</span><ul><li><a class="tocitem" href="../interface/">Working with Losses</a></li><li class="is-active"><a class="tocitem" href>Efficient Sum and Mean</a><ul class="internal"><li><a class="tocitem" href="#Aggregation-Modes"><span>Aggregation Modes</span></a></li><li><a class="tocitem" href="#Unweighted-Sum-and-Mean"><span>Unweighted Sum and Mean</span></a></li><li><a class="tocitem" href="#Weighted-Sum-and-Mean"><span>Weighted Sum and Mean</span></a></li></ul></li></ul></li><li><span class="tocitem">Available Losses</span><ul><li><a class="tocitem" href="../../losses/distance/">Distance-based Losses</a></li><li><a class="tocitem" href="../../losses/margin/">Margin-based Losses</a></li><li><a class="tocitem" href="../../losses/other/">Other Losses</a></li></ul></li><li><span class="tocitem">Advances Topics</span><ul><li><a class="tocitem" href="../../advanced/extend/">Altering existing Losses</a></li><li><a class="tocitem" href="../../advanced/developer/">Developer Documentation</a></li></ul></li><li><a class="tocitem" href="../../acknowledgements/">Acknowledgements</a></li><li><a class="tocitem" href="../../LICENSE/">LICENSE</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">User&#39;s Guide</a></li><li class="is-active"><a href>Efficient Sum and Mean</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Efficient Sum and Mean</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaML/LossFunctions.jl/blob/master/docs/src/user/aggregate.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Efficient-Sum-and-Mean"><a class="docs-heading-anchor" href="#Efficient-Sum-and-Mean">Efficient Sum and Mean</a><a id="Efficient-Sum-and-Mean-1"></a><a class="docs-heading-anchor-permalink" href="#Efficient-Sum-and-Mean" title="Permalink"></a></h1><p>In many situations we are not really that interested in the individual loss values (or derivatives) of each observation, but the sum or mean of them; be it weighted or unweighted. For example, by computing the unweighted mean of the loss for our training set, we would effectively compute what is known as the empirical risk. This is usually the quantity (or an important part of it) that we are interesting in minimizing.</p><p>When we say &quot;weighted&quot; or &quot;unweighted&quot;, we are referring to whether we are explicitly specifying the influence of individual observations on the result. &quot;Weighing&quot; an observation is achieved by multiplying its value with some number (i.e. the &quot;weight&quot; of that observation). As a consequence that weighted observation will have a stronger or weaker influence on the result. In order to weigh an observation we have to know which array dimension (if there are more than one) denotes the observations. On the other hand, for computing an unweighted result we don&#39;t actually need to know anything about the meaning of the array dimensions, as long as the <code>targets</code> and the <code>outputs</code> are of compatible shape and size.</p><p>The naive way to compute such an unweighted reduction, would be to call <code>mean</code> or <code>sum</code> on the result of the element-wise operation. The following code snipped show an example of that. We say &quot;naive&quot;, because it will not give us an acceptable performance.</p><pre><code class="language-julia-repl hljs">julia&gt; value(L1DistLoss(), [2,5,-2], [1.,2,3])
3-element Vector{Float64}:
 1.0
 3.0
 5.0

julia&gt; sum(value(L1DistLoss(), [2,5,-2], [1.,2,3])) # WARNING: Bad code
9.0</code></pre><p>This works as expected, but there is a price for it. Before the sum can be computed, <a href="../interface/#LossFunctions.value"><code>value</code></a> will allocate a temporary array and fill it with the element-wise results. After that, <code>sum</code> will iterate over this temporary array and accumulate the values accordingly. Bottom line: we allocate temporary memory that we don&#39;t need in the end and could avoid.</p><p>For that reason we provide special methods that compute the common accumulations efficiently without allocating temporary arrays. These methods can be invoked using an additional parameter which specifies how the values should be accumulated / averaged. The type of this parameter has to be a subtype of <code>AggregateMode</code>.</p><h2 id="Aggregation-Modes"><a class="docs-heading-anchor" href="#Aggregation-Modes">Aggregation Modes</a><a id="Aggregation-Modes-1"></a><a class="docs-heading-anchor-permalink" href="#Aggregation-Modes" title="Permalink"></a></h2><p>Before we discuss these memory-efficient methods, let us briefly introduce the available aggregation mode types. We provide a number of different aggregation modes, all of which are contained within the namespace <code>AggMode</code>. An instance of such type can then be used as additional parameter to <a href="../interface/#LossFunctions.value"><code>value</code></a>, <a href="../interface/#LossFunctions.deriv"><code>deriv</code></a>, and <a href="../interface/#LossFunctions.deriv2"><code>deriv2</code></a>, as we will see further down.</p><p>It follows a list of available aggregation modes. Each of which with a short description of what their effect would be when used as an additional parameter to the functions mentioned above.</p><article class="docstring"><header><a class="docstring-binding" id="LossFunctions.AggMode.None" href="#LossFunctions.AggMode.None"><code>LossFunctions.AggMode.None</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AggMode.None()</code></pre><p>Opt-out of aggregation. This is usually the default value. Using <code>None</code> will cause the element-wise results to be returned.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaML/LossFunctions.jl/blob/cee8cde8d3927f9dfc3704bd709ed14de9d2b879/src/aggmode.jl#L20-L25">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LossFunctions.AggMode.Sum" href="#LossFunctions.AggMode.Sum"><code>LossFunctions.AggMode.Sum</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AggMode.Sum()</code></pre><p>Causes the method to return the unweighted sum of the elements instead of the individual elements. Can be used in combination with <code>ObsDim</code>, in which case a vector will be returned containing the sum for each observation (useful mainly for multivariable regression).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaML/LossFunctions.jl/blob/cee8cde8d3927f9dfc3704bd709ed14de9d2b879/src/aggmode.jl#L28-L36">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LossFunctions.AggMode.Mean" href="#LossFunctions.AggMode.Mean"><code>LossFunctions.AggMode.Mean</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AggMode.Mean()</code></pre><p>Causes the method to return the unweighted mean of the elements instead of the individual elements. Can be used in combination with <code>ObsDim</code>, in which case a vector will be returned containing the mean for each observation (useful mainly for multivariable regression).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaML/LossFunctions.jl/blob/cee8cde8d3927f9dfc3704bd709ed14de9d2b879/src/aggmode.jl#L39-L47">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LossFunctions.AggMode.WeightedSum" href="#LossFunctions.AggMode.WeightedSum"><code>LossFunctions.AggMode.WeightedSum</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AggMode.WeightedSum(weights; [normalize = false])</code></pre><p>Causes the method to return the weighted sum of all observations. The variable <code>weights</code> has to be a vector of the same length as the number of observations. If <code>normalize = true</code>, the values of the weight vector will be normalized in such as way that they sum to one.</p><p><strong>Arguments</strong></p><ul><li><p><code>weights::AbstractVector</code>: Vector of weight values that can be used to give certain observations a stronger influence on the sum.</p></li><li><p><code>normalize::Bool</code>: Boolean that specifies if the weight vector should be transformed in such a way that it sums to one (i.e. normalized). This will not mutate the weight vector but instead happen on the fly during the accumulation.</p><p>Defaults to <code>false</code>. Setting it to <code>true</code> only really makes sense in multivalue-regression, otherwise the result will be the same as for <a href="#LossFunctions.AggMode.WeightedMean"><code>WeightedMean</code></a>.</p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaML/LossFunctions.jl/blob/cee8cde8d3927f9dfc3704bd709ed14de9d2b879/src/aggmode.jl#L50-L74">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LossFunctions.AggMode.WeightedMean" href="#LossFunctions.AggMode.WeightedMean"><code>LossFunctions.AggMode.WeightedMean</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AggMode.WeightedMean(weights; [normalize = true])</code></pre><p>Causes the method to return the weighted mean of all observations. The variable <code>weights</code> has to be a vector of the same length as the number of observations. If <code>normalize = true</code>, the values of the weight vector will be normalized in such as way that they sum to one.</p><p><strong>Arguments</strong></p><ul><li><p><code>weights::AbstractVector</code>: Vector of weight values that can be used to give certain observations a stronger influence on the mean.</p></li><li><p><code>normalize::Bool</code>: Boolean that specifies if the weight vector should be transformed in such a way that it sums to one (i.e. normalized). This will not mutate the weight vector but instead happen on the fly during the accumulation.</p><p>Defaults to <code>true</code>. Setting it to <code>false</code> only really makes sense in multivalue-regression, otherwise the result will be the same as for <a href="#LossFunctions.AggMode.WeightedSum"><code>WeightedSum</code></a>.</p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaML/LossFunctions.jl/blob/cee8cde8d3927f9dfc3704bd709ed14de9d2b879/src/aggmode.jl#L81-L105">source</a></section></article><h2 id="Unweighted-Sum-and-Mean"><a class="docs-heading-anchor" href="#Unweighted-Sum-and-Mean">Unweighted Sum and Mean</a><a id="Unweighted-Sum-and-Mean-1"></a><a class="docs-heading-anchor-permalink" href="#Unweighted-Sum-and-Mean" title="Permalink"></a></h2><p>As hinted before, we provide special memory efficient methods for computing the <strong>sum</strong> or the <strong>mean</strong> of the element-wise (or broadcasted) results of <a href="../interface/#LossFunctions.value"><code>value</code></a>, <a href="../interface/#LossFunctions.deriv"><code>deriv</code></a>, and <a href="../interface/#LossFunctions.deriv2"><code>deriv2</code></a>. These methods avoid the allocation of a temporary array and instead compute the result directly.</p><h2 id="Weighted-Sum-and-Mean"><a class="docs-heading-anchor" href="#Weighted-Sum-and-Mean">Weighted Sum and Mean</a><a id="Weighted-Sum-and-Mean-1"></a><a class="docs-heading-anchor-permalink" href="#Weighted-Sum-and-Mean" title="Permalink"></a></h2><p>Up to this point, all the averaging was performed in an unweighted manner. That means that each observation was treated as equal and had thus the same potential influence on the result. In this sub-section we will consider the situations in which we do want to explicitly specify the influence of each observation (i.e. we want to weigh them). When we say we &quot;weigh&quot; an observation, what it effectively boils down to is multiplying the result for that observation (i.e. the computed loss or derivative) with some number. This is done for every observation individually.</p><p>To get a better understand of what we are talking about, let us consider performing a weighting scheme manually. The following code will compute the loss for three observations, and then multiply the result of the second observation with the number <code>2</code>, while the other two remains as they are. If we then sum up the results, we will see that the loss of the second observation was effectively counted twice.</p><pre><code class="language-julia-repl hljs">julia&gt; result = value.(L1DistLoss(), [2,5,-2], [1.,2,3]) .* [1,2,1]
3-element Vector{Float64}:
 1.0
 6.0
 5.0

julia&gt; sum(result)
12.0</code></pre><p>The point of weighing observations is to inform the learning algorithm we are working with, that it is more important to us to predict some observations correctly than it is for others. So really, the concrete weight-factor matters less than the ratio between the different weights. In the example above the second observation was thus considered twice as important as any of the other two observations.</p><p>In the case of multi-dimensional arrays the process isn&#39;t that simple anymore. In such a scenario, computing the weighted sum (or weighted mean) can be thought of as having an additional step. First we either compute the sum or (unweighted) average for each observation (which results in a vector), and then we compute the weighted sum of all observations.</p><p>The following code snipped demonstrates how to compute the <code>AggMode.WeightedSum([2,1])</code> manually. This is <strong>not</strong> meant as an example of how to do it, but simply to show what is happening qualitatively. In this example we assume that we are working in a multi-variable regression setting, in which our data set has four observations with two target-variables each.</p><pre><code class="language-julia-repl hljs">julia&gt; targets = reshape(1:8, (2, 4)) ./ 8
2×4 Matrix{Float64}:
 0.125  0.375  0.625  0.875
 0.25   0.5    0.75   1.0

julia&gt; outputs = reshape(1:2:16, (2, 4)) ./ 8
2×4 Matrix{Float64}:
 0.125  0.625  1.125  1.625
 0.375  0.875  1.375  1.875

julia&gt; # WARNING: BAD CODE - ONLY FOR ILLUSTRATION

julia&gt; tmp = sum(value.(L1DistLoss(), outputs, targets), dims=2)
2×1 Matrix{Float64}:
 1.5
 2.0

julia&gt; sum(tmp .* [2, 1]) # weigh 1st observation twice as high
5.0</code></pre><p>To manually compute the result for <code>AggMode.WeightedMean([2,1])</code> we follow a similar approach, but use the normalized weight vector in the last step.</p><pre><code class="language-julia-repl hljs">julia&gt; using Statistics # for access to &quot;mean&quot;

julia&gt; # WARNING: BAD CODE - ONLY FOR ILLUSTRATION

julia&gt; tmp = mean(value.(L1DistLoss(), outputs, targets), dims=2)
2×1 Matrix{Float64}:
 0.375
 0.5

julia&gt; sum(tmp .* [0.6666, 0.3333]) # weigh 1st observation twice as high
0.416625</code></pre><p>Note that you can specify explicitly if you want to normalize the weight vector. That option is supported for computing the weighted sum, as well as for computing the weighted mean. See the documentation for <a href="#LossFunctions.AggMode.WeightedSum"><code>AggMode.WeightedSum</code></a> and <a href="#LossFunctions.AggMode.WeightedMean"><code>AggMode.WeightedMean</code></a> for more information.</p><p>The code-snippets above are of course very inefficient, because they allocate (multiple) temporary arrays. We only included them to demonstrate what is happening in terms of desired result / effect. For doing those computations efficiently we provide special methods for <a href="../interface/#LossFunctions.value"><code>value</code></a>, <a href="../interface/#LossFunctions.deriv"><code>deriv</code></a>, <a href="../interface/#LossFunctions.deriv2"><code>deriv2</code></a> and their mutating counterparts.</p><pre><code class="language-julia-repl hljs">julia&gt; value(L1DistLoss(), [2,5,-2], [1.,2,3], AggMode.WeightedSum([1,2,1]))
12.0

julia&gt; value(L1DistLoss(), [2,5,-2], [1.,2,3], AggMode.WeightedMean([1,2,1]))
1.0</code></pre><p>We also provide this functionality for <a href="../interface/#LossFunctions.deriv"><code>deriv</code></a> and <a href="../interface/#LossFunctions.deriv2"><code>deriv2</code></a> respectively.</p><pre><code class="language-julia-repl hljs">julia&gt; deriv(L2DistLoss(), [2,5,-2], [1.,2,3], AggMode.WeightedSum([1,2,1]))
4.0

julia&gt; deriv(L2DistLoss(), [2,5,-2], [1.,2,3], AggMode.WeightedMean([1,2,1]))
0.3333333333333333</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../interface/">« Working with Losses</a><a class="docs-footer-nextpage" href="../../losses/distance/">Distance-based Losses »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Sunday 23 April 2023 23:50">Sunday 23 April 2023</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
