<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Developer Documentation · LossFunctions.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/documenter.css" rel="stylesheet" type="text/css"/><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="../../assets/style.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><a href="../../index.html"><img class="logo" src="../../assets/logo.png" alt="LossFunctions.jl logo"/></a><h1>LossFunctions.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><span class="toctext">Introduction</span><ul><li><a class="toctext" href="../../introduction/gettingstarted/">Getting Started</a></li><li><a class="toctext" href="../../introduction/motivation/">Background and Motivation</a></li></ul></li><li><span class="toctext">User&#39;s Guide</span><ul><li><a class="toctext" href="../../user/interface/">Working with Losses</a></li><li><a class="toctext" href="../../user/aggregate/">Efficient Sum and Mean</a></li></ul></li><li><span class="toctext">Available Losses</span><ul><li><a class="toctext" href="../../losses/distance/">Distance-based Losses</a></li><li><a class="toctext" href="../../losses/margin/">Margin-based Losses</a></li></ul></li><li><span class="toctext">Advances Topics</span><ul><li><a class="toctext" href="../extend/">Altering existing Losses</a></li><li class="current"><a class="toctext" href>Developer Documentation</a><ul class="internal"><li><a class="toctext" href="#Abstract-Types-1">Abstract Types</a></li><li><a class="toctext" href="#Shared-Interface-1">Shared Interface</a></li></ul></li></ul></li><li><a class="toctext" href="../../acknowledgements/">Acknowledgements</a></li><li><a class="toctext" href="../../LICENSE/">LICENSE</a></li></ul></nav><article id="docs"><header><nav><ul><li>Advances Topics</li><li><a href>Developer Documentation</a></li></ul><a class="edit-page" href="https://github.com/JuliaML/LossFunctions.jl/blob/master/docs/src/advanced/developer.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Developer Documentation</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Developer-Documentation-1" href="#Developer-Documentation-1">Developer Documentation</a></h1><p>In this part of the documentation we will discuss some of the internal design aspects of this library. Consequently, the target audience of this section and its sub-sections is primarily people interested in contributing to this package. As such, the information provided here should be of little to no relevance for users interested in simply applying the package.</p><h2><a class="nav-anchor" id="Abstract-Types-1" href="#Abstract-Types-1">Abstract Types</a></h2><p>We have seen in previous sections, that many families of loss functions are implemented as immutable types with free parameters. An example for such a family is the <a href="../../losses/distance/#LossFunctions.L1EpsilonInsLoss"><code>L1EpsilonInsLoss</code></a>, which represents all the <span>$\epsilon$</span>-insensitive loss-functions for each possible value of <span>$\epsilon$</span>.</p><p>Aside from these special families, there a handful of more generic families that between them contain almost all of the loss functions this package implements. These families are defined as abstract types in the type tree. Their main purpose is two-fold:</p><ul><li><p>From an end-user&#39;s perspective, they are most useful for dispatching on the particular kind of prediction problem that they are intended for (regression vs classification).</p></li><li><p>Form an implementation perspective, these abstract types allow us to implement shared functionality and fall-back methods, or even allow for a simpler implementation.</p></li></ul><p>Most of the implemented loss functions fall under the umbrella of supervised losses. As such, we barely mention other types of losses anywhere in this documentation.</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="LearnBase.SupervisedLoss" href="#LearnBase.SupervisedLoss"><code>LearnBase.SupervisedLoss</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>A loss is considered <strong>supervised</strong>, if all the information needed to compute <code>L(features, targets, outputs)</code> are contained in <code>targets</code> and <code>outputs</code>, and thus allows for the simplification <code>L(targets, outputs)</code>.</p></div></div></section><p>There are two interesting sub-families of supervised loss functions.  One of these families is called distance-based. All losses that belong to this family are implemented as subtype of the abstract type <a href="#LearnBase.DistanceLoss"><code>DistanceLoss</code></a>, which itself is subtype of <a href="#LearnBase.SupervisedLoss"><code>SupervisedLoss</code></a>.</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="LearnBase.DistanceLoss" href="#LearnBase.DistanceLoss"><code>LearnBase.DistanceLoss</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>A supervised loss that can be simplified to <code>L(targets, outputs) = L(targets - outputs)</code> is considered distance-based.</p></div></div></section><p>The second core sub-family of supervised losses is called margin-based. All loss functions that belong to this family are implemented as subtype of the abstract type <a href="#LearnBase.MarginLoss"><code>MarginLoss</code></a>, which itself is subtype of <a href="#LearnBase.SupervisedLoss"><code>SupervisedLoss</code></a>.</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="LearnBase.MarginLoss" href="#LearnBase.MarginLoss"><code>LearnBase.MarginLoss</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>A supervised loss, where the targets are in {-1, 1}, and which can be simplified to <code>L(targets, outputs) = L(targets * outputs)</code> is considered <strong>margin-based</strong>.</p></div></div></section><h2><a class="nav-anchor" id="Shared-Interface-1" href="#Shared-Interface-1">Shared Interface</a></h2><p>Each of the three abstract types listed above serves a purpose other than dispatch. All losses that belong to the same family share functionality to some degree. For example all subtypes of <a href="#LearnBase.SupervisedLoss"><code>SupervisedLoss</code></a> share the same implementations for the vectorized versions of <a href="../../user/aggregate/#LearnBase.value-Tuple{Loss,AbstractArray,AbstractArray,LossFunctions.AverageMode}"><code>value</code></a> and <a href="../../user/aggregate/#LearnBase.deriv-Tuple{Loss,AbstractArray,AbstractArray,LossFunctions.AverageMode}"><code>deriv</code></a>.</p><p>More interestingly, the abstract types <a href="#LearnBase.DistanceLoss"><code>DistanceLoss</code></a> and <a href="#LearnBase.MarginLoss"><code>MarginLoss</code></a>, serve an additional purpose aside from shared functionality. We have seen in the background section what it is that makes a loss margin-based or distance-based. Without repeating the definition let us state that it boils down to the existence of a <em>representing function</em> <span>$\psi$</span>, which allows to compute a loss using a unary function instead of a binary one. Indeed, all the subtypes of <a href="#LearnBase.DistanceLoss"><code>DistanceLoss</code></a> and <a href="#LearnBase.MarginLoss"><code>MarginLoss</code></a> are implemented in the unary form of their representing function.</p><h3><a class="nav-anchor" id="Distance-based-Losses-1" href="#Distance-based-Losses-1">Distance-based Losses</a></h3><p>Supervised losses that can be expressed as a univariate function of <code>output - target</code> are referred to as distance-based losses. Distance-based losses are typically utilized for regression problems. That said, there are also other losses that are useful for regression problems that don&#39;t fall into this category, such as the <a href="../../losses/distance/#LossFunctions.PeriodicLoss"><code>PeriodicLoss</code></a>.</p><h3><a class="nav-anchor" id="Margin-based-Losses-1" href="#Margin-based-Losses-1">Margin-based Losses</a></h3><p>Margin-based losses are supervised losses where the values of the targets are restricted to be in <span>$\{1,-1\}$</span>, and which can be expressed as a univariate function <code>output * target</code>.</p><footer><hr/><a class="previous" href="../extend/"><span class="direction">Previous</span><span class="title">Altering existing Losses</span></a><a class="next" href="../../indices/"><span class="direction">Next</span><span class="title">Indices</span></a></footer></article></body></html>
