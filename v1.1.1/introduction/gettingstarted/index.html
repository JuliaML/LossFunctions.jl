<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Getting Started · LossFunctions.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://JuliaML.github.io/LossFunctions.jl/introduction/gettingstarted/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/style.css" rel="stylesheet" type="text/css"/><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="LossFunctions.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">LossFunctions.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><span class="tocitem">Introduction</span><ul><li class="is-active"><a class="tocitem" href>Getting Started</a><ul class="internal"><li><a class="tocitem" href="#Installation"><span>Installation</span></a></li><li><a class="tocitem" href="#Overview"><span>Overview</span></a></li><li><a class="tocitem" href="#Getting-Help"><span>Getting Help</span></a></li></ul></li><li><a class="tocitem" href="../motivation/">Background and Motivation</a></li></ul></li><li><span class="tocitem">User&#39;s Guide</span><ul><li><a class="tocitem" href="../../user/interface/">Working with Losses</a></li><li><a class="tocitem" href="../../user/aggregate/">Efficient Sum and Mean</a></li></ul></li><li><span class="tocitem">Available Losses</span><ul><li><a class="tocitem" href="../../losses/distance/">Distance-based Losses</a></li><li><a class="tocitem" href="../../losses/margin/">Margin-based Losses</a></li><li><a class="tocitem" href="../../losses/other/">Other Losses</a></li></ul></li><li><span class="tocitem">Advances Topics</span><ul><li><a class="tocitem" href="../../advanced/extend/">Altering existing Losses</a></li><li><a class="tocitem" href="../../advanced/developer/">Developer Documentation</a></li></ul></li><li><a class="tocitem" href="../../acknowledgements/">Acknowledgements</a></li><li><a class="tocitem" href="../../LICENSE/">LICENSE</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Introduction</a></li><li class="is-active"><a href>Getting Started</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Getting Started</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaML/LossFunctions.jl/blob/master/docs/src/introduction/gettingstarted.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Getting-Started"><a class="docs-heading-anchor" href="#Getting-Started">Getting Started</a><a id="Getting-Started-1"></a><a class="docs-heading-anchor-permalink" href="#Getting-Started" title="Permalink"></a></h1><p>LossFunctions.jl is the result of a collaborative effort to design and implement an efficient but also convenient-to-use <a href="https://julialang.org">Julia</a> library for, well, loss functions. As such, this package implements the functionality needed to query various properties about a loss function (such as convexity), as well as a number of methods to compute its value, derivative, and second derivative for single observations or arrays of observations.</p><p>In this section we will provide a condensed overview of the package. In order to keep this overview concise, we will not discuss any background information or theory on the losses here in detail.</p><h2 id="Installation"><a class="docs-heading-anchor" href="#Installation">Installation</a><a id="Installation-1"></a><a class="docs-heading-anchor-permalink" href="#Installation" title="Permalink"></a></h2><p>To install <a href="https://github.com/JuliaML/LossFunctions.jl">LossFunctions.jl</a>, start up Julia and type the following code-snipped into the REPL. It makes use of the native Julia package manager.</p><pre><code class="language-julia hljs">] add LossFunctions</code></pre><h2 id="Overview"><a class="docs-heading-anchor" href="#Overview">Overview</a><a id="Overview-1"></a><a class="docs-heading-anchor-permalink" href="#Overview" title="Permalink"></a></h2><p>Let us take a look at a few examples to get a feeling of how one can use this library. This package is registered in the Julia package ecosystem. Once installed the package can be imported as usual.</p><pre><code class="language-julia hljs">using LossFunctions</code></pre><p>Typically, the losses we work with in Machine Learning are multivariate functions of two variables, the <strong>true target</strong> <span>$y$</span>, which represents the &quot;ground truth&quot; (i.e. correct answer), and the <strong>predicted output</strong> <span>$\hat{y}$</span>, which is what our model thinks the truth is. All losses that can be expressed in this way will be referred to as supervised losses. The true targets are often expected to be of a specific set (e.g. <span>$\{1,-1\}$</span> in classification), which we will refer to as <span>$Y$</span>, while the predicted outputs may be any real number. So for our purposes we can define a supervised loss as follows</p><p class="math-container">\[L : \mathbb{R} \times Y \rightarrow [0,\infty)\]</p><p>Such a loss function takes these two variables as input and returns a value that quantifies how &quot;bad&quot; our prediction is in comparison to the truth. In other words: the lower the loss, the better the prediction.</p><p>From an implementation perspective, we should point out that all the concrete loss &quot;functions&quot; that this package provides are actually defined as immutable types, instead of native Julia functions. We can compute the value of some type of loss using the functor interface. Let us start with an example of how to compute the loss of a single observation (i.e. two numbers).</p><pre><code class="language-julia-repl hljs">#         loss       ŷ    y
julia&gt; L2DistLoss()(0.5, 1.0)
0.25</code></pre><p>Calling the same function using arrays instead of numbers will return the element-wise results, and thus basically just serve as a wrapper for broadcast (which by the way is also supported).</p><pre><code class="language-julia-repl hljs">julia&gt; true_targets = [  1,  0, -2];

julia&gt; pred_outputs = [0.5,  2, -1];

julia&gt; L2DistLoss().(pred_outputs, true_targets)
3-element Vector{Float64}:
 0.25
 4.0
 1.0</code></pre><p>If you are not actually interested in the element-wise results individually, but some accumulation of those (such as mean or sum), you can additionally specify an <strong>aggregation mode</strong>. This will avoid allocating a temporary array and directly compute the result.</p><pre><code class="language-julia-repl hljs">julia&gt; sum(L2DistLoss(), pred_outputs, true_targets)
5.25

julia&gt; mean(L2DistLoss(), pred_outputs, true_targets)
1.75</code></pre><p>Aside from these standard unweighted average modes, we also provide weighted alternatives. These expect a weight-factor for each observation in the predicted outputs and so allow to give certain observations a stronger influence over the result.</p><pre><code class="language-julia-repl hljs">julia&gt; sum(L2DistLoss(), pred_outputs, true_targets, [2,1,1], normalize=false)
5.5

julia&gt; mean(L2DistLoss(), pred_outputs, true_targets, [2,1,1], normalize=false)
1.8333333333333333</code></pre><h2 id="Getting-Help"><a class="docs-heading-anchor" href="#Getting-Help">Getting Help</a><a id="Getting-Help-1"></a><a class="docs-heading-anchor-permalink" href="#Getting-Help" title="Permalink"></a></h2><p>To get help on specific functionality you can either look up the information here, or if you prefer you can make use of Julia&#39;s native doc-system. The following example shows how to get additional information on <a href="../../losses/margin/#LossFunctions.L1HingeLoss"><code>L1HingeLoss</code></a> within Julia&#39;s REPL:</p><pre><code class="language-julia hljs">?L1HingeLoss</code></pre><p>If you find yourself stuck or have other questions concerning the package you can find us on the Julia&#39;s Zulip chat or the <em>Machine Learning</em> domain on Discourse:</p><ul><li><a href="https://discourse.julialang.org/c/domain/ML">Machine Learning in Julia</a></li></ul><p>If you encounter a bug or would like to participate in the further development of this package come find us on Github.</p><ul><li><a href="https://github.com/JuliaML/LossFunctions.jl">JuliaML/LossFunctions.jl</a></li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../">« Home</a><a class="docs-footer-nextpage" href="../motivation/">Background and Motivation »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Wednesday 27 August 2025 13:45">Wednesday 27 August 2025</span>. Using Julia version 1.11.6.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
