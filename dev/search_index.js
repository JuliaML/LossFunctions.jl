var documenterSearchIndex = {"docs":
[{"location":"losses/other/#Other-Losses","page":"Other Losses","title":"Other Losses","text":"","category":"section"},{"location":"losses/other/","page":"Other Losses","title":"Other Losses","text":"Loss functions exist that are not based on distances nor margins. This section lists other useful losses that are implemented in the package:","category":"page"},{"location":"losses/other/#MisclassLoss","page":"Other Losses","title":"MisclassLoss","text":"","category":"section"},{"location":"losses/other/","page":"Other Losses","title":"Other Losses","text":"MisclassLoss","category":"page"},{"location":"losses/other/#LossFunctions.MisclassLoss","page":"Other Losses","title":"LossFunctions.MisclassLoss","text":"MisclassLoss{R<:AbstractFloat} <: SupervisedLoss\n\nMisclassification loss that assigns 1 for misclassified examples and 0 otherwise. It is a generalization of ZeroOneLoss for more than two classes.\n\nThe type parameter R specifies the result type of the loss. Default type is double precision R = Float64.\n\n\n\n","category":"type"},{"location":"losses/other/#PoissonLoss","page":"Other Losses","title":"PoissonLoss","text":"","category":"section"},{"location":"losses/other/","page":"Other Losses","title":"Other Losses","text":"PoissonLoss","category":"page"},{"location":"losses/other/#LossFunctions.PoissonLoss","page":"Other Losses","title":"LossFunctions.PoissonLoss","text":"PoissonLoss <: SupervisedLoss\n\nLoss under a Poisson noise distribution (KL-divergence)\n\nL(output target) = exp(output) - target*output\n\n\n\n","category":"type"},{"location":"losses/other/#CrossEntropyLoss","page":"Other Losses","title":"CrossEntropyLoss","text":"","category":"section"},{"location":"losses/other/","page":"Other Losses","title":"Other Losses","text":"CrossEntropyLoss","category":"page"},{"location":"losses/other/#LossFunctions.CrossEntropyLoss","page":"Other Losses","title":"LossFunctions.CrossEntropyLoss","text":"CrossEntropyLoss <: SupervisedLoss\n\nThe cross-entropy loss is defined as:\n\nL(output target) = - target*log(output) - (1-target)*log(1-output)\n\n\n\n","category":"type"},{"location":"indices/#Functions","page":"Indices","title":"Functions","text":"","category":"section"},{"location":"indices/","page":"Indices","title":"Indices","text":"Order   = [:function]","category":"page"},{"location":"indices/#Types","page":"Indices","title":"Types","text":"","category":"section"},{"location":"indices/","page":"Indices","title":"Indices","text":"Order   = [:type]","category":"page"},{"location":"advanced/developer/#Developer-Documentation","page":"Developer Documentation","title":"Developer Documentation","text":"","category":"section"},{"location":"advanced/developer/","page":"Developer Documentation","title":"Developer Documentation","text":"In this part of the documentation we will discuss some of the internal design aspects of this library. Consequently, the target audience of this section and its sub-sections is primarily people interested in contributing to this package. As such, the information provided here should be of little to no relevance for users interested in simply applying the package.","category":"page"},{"location":"advanced/developer/#Abstract-Types","page":"Developer Documentation","title":"Abstract Types","text":"","category":"section"},{"location":"advanced/developer/","page":"Developer Documentation","title":"Developer Documentation","text":"We have seen in previous sections, that many families of loss functions are implemented as immutable types with free parameters. An example for such a family is the L1EpsilonInsLoss, which represents all the epsilon-insensitive loss-functions for each possible value of epsilon.","category":"page"},{"location":"advanced/developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Aside from these special families, there a handful of more generic families that between them contain almost all of the loss functions this package implements. These families are defined as abstract types in the type tree. Their main purpose is two-fold:","category":"page"},{"location":"advanced/developer/","page":"Developer Documentation","title":"Developer Documentation","text":"From an end-user's perspective, they are most useful for dispatching on the particular kind of prediction problem that they are intended for (regression vs classification).\nForm an implementation perspective, these abstract types allow us to implement shared functionality and fall-back methods, or even allow for a simpler implementation.","category":"page"},{"location":"advanced/developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Most of the implemented loss functions fall under the umbrella of supervised losses. As such, we barely mention other types of losses anywhere in this documentation.","category":"page"},{"location":"advanced/developer/","page":"Developer Documentation","title":"Developer Documentation","text":"SupervisedLoss","category":"page"},{"location":"advanced/developer/#LossFunctions.SupervisedLoss","page":"Developer Documentation","title":"LossFunctions.SupervisedLoss","text":"A loss is considered supervised, if all the information needed to compute L(x, ŷ, y) are contained in ŷ and y, and thus allows for the simplification L(ŷ, y).\n\n\n\n\n\n","category":"type"},{"location":"advanced/developer/","page":"Developer Documentation","title":"Developer Documentation","text":"There are two interesting sub-families of supervised loss functions.  One of these families is called distance-based. All losses that belong to this family are implemented as subtype of the abstract type DistanceLoss, which itself is subtype of SupervisedLoss.","category":"page"},{"location":"advanced/developer/","page":"Developer Documentation","title":"Developer Documentation","text":"DistanceLoss","category":"page"},{"location":"advanced/developer/#LossFunctions.DistanceLoss","page":"Developer Documentation","title":"LossFunctions.DistanceLoss","text":"A supervised loss that can be simplified to L(ŷ, y) = L(ŷ - y) is considered distance-based.\n\n\n\n\n\n","category":"type"},{"location":"advanced/developer/","page":"Developer Documentation","title":"Developer Documentation","text":"The second core sub-family of supervised losses is called margin-based. All loss functions that belong to this family are implemented as subtype of the abstract type MarginLoss, which itself is subtype of SupervisedLoss.","category":"page"},{"location":"advanced/developer/","page":"Developer Documentation","title":"Developer Documentation","text":"MarginLoss","category":"page"},{"location":"advanced/developer/#LossFunctions.MarginLoss","page":"Developer Documentation","title":"LossFunctions.MarginLoss","text":"A supervised loss with targets y ∈ {-1, 1}, and which can be simplified to L(ŷ, y) = L(ŷ⋅y) is considered margin-based.\n\n\n\n\n\n","category":"type"},{"location":"advanced/developer/#Shared-Interface","page":"Developer Documentation","title":"Shared Interface","text":"","category":"section"},{"location":"advanced/developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Each of the three abstract types listed above serves a purpose other than dispatch. All losses that belong to the same family share functionality to some degree.","category":"page"},{"location":"advanced/developer/","page":"Developer Documentation","title":"Developer Documentation","text":"More interestingly, the abstract types DistanceLoss and MarginLoss, serve an additional purpose aside from shared functionality. We have seen in the background section what it is that makes a loss margin-based or distance-based. Without repeating the definition let us state that it boils down to the existence of a representing function psi, which allows to compute a loss using a unary function instead of a binary one. Indeed, all the subtypes of DistanceLoss and MarginLoss are implemented in the unary form of their representing function.","category":"page"},{"location":"advanced/developer/#Distance-based-Losses","page":"Developer Documentation","title":"Distance-based Losses","text":"","category":"section"},{"location":"advanced/developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Supervised losses that can be expressed as a univariate function of output - target are referred to as distance-based losses. Distance-based losses are typically utilized for regression problems. That said, there are also other losses that are useful for regression problems that don't fall into this category, such as the PeriodicLoss.","category":"page"},{"location":"advanced/developer/#Margin-based-Losses","page":"Developer Documentation","title":"Margin-based Losses","text":"","category":"section"},{"location":"advanced/developer/","page":"Developer Documentation","title":"Developer Documentation","text":"Margin-based losses are supervised losses where the values of the targets are restricted to be in 1-1, and which can be expressed as a univariate function output * target.","category":"page"},{"location":"user/aggregate/","page":"Efficient Sum and Mean","title":"Efficient Sum and Mean","text":"DocTestSetup = quote\n    using LossFunctions\nend","category":"page"},{"location":"user/aggregate/#Efficient-Sum-and-Mean","page":"Efficient Sum and Mean","title":"Efficient Sum and Mean","text":"","category":"section"},{"location":"user/aggregate/","page":"Efficient Sum and Mean","title":"Efficient Sum and Mean","text":"In many situations we are not really that interested in the individual loss values (or derivatives) of each observation, but the sum or mean of them; be it weighted or unweighted. For example, by computing the unweighted mean of the loss for our training set, we would effectively compute what is known as the empirical risk. This is usually the quantity (or an important part of it) that we are interesting in minimizing.","category":"page"},{"location":"user/aggregate/","page":"Efficient Sum and Mean","title":"Efficient Sum and Mean","text":"When we say \"weighted\" or \"unweighted\", we are referring to whether we are explicitly specifying the influence of individual observations on the result. \"Weighing\" an observation is achieved by multiplying its value with some number (i.e. the \"weight\" of that observation). As a consequence that weighted observation will have a stronger or weaker influence on the result. In order to weigh an observation we have to know which array dimension (if there are more than one) denotes the observations. On the other hand, for computing an unweighted result we don't actually need to know anything about the meaning of the array dimensions, as long as the targets and the outputs are of compatible shape and size.","category":"page"},{"location":"user/aggregate/","page":"Efficient Sum and Mean","title":"Efficient Sum and Mean","text":"The naive way to compute such an unweighted reduction, would be to call mean or sum on the result of the element-wise operation. The following code snipped show an example of that. We say \"naive\", because it will not give us an acceptable performance.","category":"page"},{"location":"user/aggregate/","page":"Efficient Sum and Mean","title":"Efficient Sum and Mean","text":"julia> loss = L1DistLoss()\nL1DistLoss()\n\njulia> loss.([2,5,-2], [1.,2,3])\n3-element Vector{Float64}:\n 1.0\n 3.0\n 5.0\n\njulia> sum(loss.([2,5,-2], [1.,2,3])) # WARNING: Bad code\n9.0","category":"page"},{"location":"user/aggregate/","page":"Efficient Sum and Mean","title":"Efficient Sum and Mean","text":"This works as expected, but there is a price for it. Before the sum can be computed, the solution will allocate a temporary array and fill it with the element-wise results. After that, sum will iterate over this temporary array and accumulate the values accordingly. Bottom line: we allocate temporary memory that we don't need in the end and could avoid.","category":"page"},{"location":"user/aggregate/","page":"Efficient Sum and Mean","title":"Efficient Sum and Mean","text":"For that reason we provide special methods that compute the common accumulations efficiently without allocating temporary arrays.","category":"page"},{"location":"user/aggregate/","page":"Efficient Sum and Mean","title":"Efficient Sum and Mean","text":"julia> sum(L1DistLoss(), [2,5,-2], [1.,2,3])\n9.0\n\njulia> mean(L1DistLoss(), [2,5,-2], [1.,2,3])\n3.0","category":"page"},{"location":"user/aggregate/","page":"Efficient Sum and Mean","title":"Efficient Sum and Mean","text":"Up to this point, all the averaging was performed in an unweighted manner. That means that each observation was treated as equal and had thus the same potential influence on the result. In the following we will consider situations in which we do want to explicitly specify the influence of each observation (i.e. we want to weigh them). When we say we \"weigh\" an observation, what it effectively boils down to is multiplying the result for that observation (i.e. the computed loss) with some number. This is done for every observation individually.","category":"page"},{"location":"user/aggregate/","page":"Efficient Sum and Mean","title":"Efficient Sum and Mean","text":"To get a better understand of what we are talking about, let us consider performing a weighting scheme manually. The following code will compute the loss for three observations, and then multiply the result of the second observation with the number 2, while the other two remains as they are. If we then sum up the results, we will see that the loss of the second observation was effectively counted twice.","category":"page"},{"location":"user/aggregate/","page":"Efficient Sum and Mean","title":"Efficient Sum and Mean","text":"julia> result = L1DistLoss().([2,5,-2], [1.,2,3]) .* [1,2,1]\n3-element Vector{Float64}:\n 1.0\n 6.0\n 5.0\n\njulia> sum(result)\n12.0","category":"page"},{"location":"user/aggregate/","page":"Efficient Sum and Mean","title":"Efficient Sum and Mean","text":"The point of weighing observations is to inform the learning algorithm we are working with, that it is more important to us to predict some observations correctly than it is for others. So really, the concrete weight-factor matters less than the ratio between the different weights. In the example above the second observation was thus considered twice as important as any of the other two observations.","category":"page"},{"location":"user/aggregate/","page":"Efficient Sum and Mean","title":"Efficient Sum and Mean","text":"julia> sum(L1DistLoss(), [2,5,-2], [1.,2,3], [1,2,1], normalize=false)\n12.0\n\njulia> mean(L1DistLoss(), [2,5,-2], [1.,2,3], [1,2,1])\n1.0","category":"page"},{"location":"introduction/gettingstarted/#Getting-Started","page":"Getting Started","title":"Getting Started","text":"","category":"section"},{"location":"introduction/gettingstarted/","page":"Getting Started","title":"Getting Started","text":"LossFunctions.jl is the result of a collaborative effort to design and implement an efficient but also convenient-to-use Julia library for, well, loss functions. As such, this package implements the functionality needed to query various properties about a loss function (such as convexity), as well as a number of methods to compute its value, derivative, and second derivative for single observations or arrays of observations.","category":"page"},{"location":"introduction/gettingstarted/","page":"Getting Started","title":"Getting Started","text":"In this section we will provide a condensed overview of the package. In order to keep this overview concise, we will not discuss any background information or theory on the losses here in detail.","category":"page"},{"location":"introduction/gettingstarted/#Installation","page":"Getting Started","title":"Installation","text":"","category":"section"},{"location":"introduction/gettingstarted/","page":"Getting Started","title":"Getting Started","text":"To install LossFunctions.jl, start up Julia and type the following code-snipped into the REPL. It makes use of the native Julia package manager.","category":"page"},{"location":"introduction/gettingstarted/","page":"Getting Started","title":"Getting Started","text":"] add LossFunctions","category":"page"},{"location":"introduction/gettingstarted/#Overview","page":"Getting Started","title":"Overview","text":"","category":"section"},{"location":"introduction/gettingstarted/","page":"Getting Started","title":"Getting Started","text":"Let us take a look at a few examples to get a feeling of how one can use this library. This package is registered in the Julia package ecosystem. Once installed the package can be imported as usual.","category":"page"},{"location":"introduction/gettingstarted/","page":"Getting Started","title":"Getting Started","text":"using LossFunctions","category":"page"},{"location":"introduction/gettingstarted/","page":"Getting Started","title":"Getting Started","text":"Typically, the losses we work with in Machine Learning are multivariate functions of two variables, the true target y, which represents the \"ground truth\" (i.e. correct answer), and the predicted output haty, which is what our model thinks the truth is. All losses that can be expressed in this way will be referred to as supervised losses. The true targets are often expected to be of a specific set (e.g. 1-1 in classification), which we will refer to as Y, while the predicted outputs may be any real number. So for our purposes we can define a supervised loss as follows","category":"page"},{"location":"introduction/gettingstarted/","page":"Getting Started","title":"Getting Started","text":"L  mathbbR times Y rightarrow 0infty)","category":"page"},{"location":"introduction/gettingstarted/","page":"Getting Started","title":"Getting Started","text":"Such a loss function takes these two variables as input and returns a value that quantifies how \"bad\" our prediction is in comparison to the truth. In other words: the lower the loss, the better the prediction.","category":"page"},{"location":"introduction/gettingstarted/","page":"Getting Started","title":"Getting Started","text":"From an implementation perspective, we should point out that all the concrete loss \"functions\" that this package provides are actually defined as immutable types, instead of native Julia functions. We can compute the value of some type of loss using the functor interface. Let us start with an example of how to compute the loss of a single observation (i.e. two numbers).","category":"page"},{"location":"introduction/gettingstarted/","page":"Getting Started","title":"Getting Started","text":"#         loss       ŷ    y\njulia> L2DistLoss()(0.5, 1.0)\n0.25","category":"page"},{"location":"introduction/gettingstarted/","page":"Getting Started","title":"Getting Started","text":"Calling the same function using arrays instead of numbers will return the element-wise results, and thus basically just serve as a wrapper for broadcast (which by the way is also supported).","category":"page"},{"location":"introduction/gettingstarted/","page":"Getting Started","title":"Getting Started","text":"julia> true_targets = [  1,  0, -2];\n\njulia> pred_outputs = [0.5,  2, -1];\n\njulia> L2DistLoss().(pred_outputs, true_targets)\n3-element Vector{Float64}:\n 0.25\n 4.0\n 1.0","category":"page"},{"location":"introduction/gettingstarted/","page":"Getting Started","title":"Getting Started","text":"If you are not actually interested in the element-wise results individually, but some accumulation of those (such as mean or sum), you can additionally specify an aggregation mode. This will avoid allocating a temporary array and directly compute the result.","category":"page"},{"location":"introduction/gettingstarted/","page":"Getting Started","title":"Getting Started","text":"julia> sum(L2DistLoss(), pred_outputs, true_targets)\n5.25\n\njulia> mean(L2DistLoss(), pred_outputs, true_targets)\n1.75","category":"page"},{"location":"introduction/gettingstarted/","page":"Getting Started","title":"Getting Started","text":"Aside from these standard unweighted average modes, we also provide weighted alternatives. These expect a weight-factor for each observation in the predicted outputs and so allow to give certain observations a stronger influence over the result.","category":"page"},{"location":"introduction/gettingstarted/","page":"Getting Started","title":"Getting Started","text":"julia> sum(L2DistLoss(), pred_outputs, true_targets, [2,1,1], normalize=false)\n5.5\n\njulia> mean(L2DistLoss(), pred_outputs, true_targets, [2,1,1], normalize=false)\n1.8333333333333333","category":"page"},{"location":"introduction/gettingstarted/#Getting-Help","page":"Getting Started","title":"Getting Help","text":"","category":"section"},{"location":"introduction/gettingstarted/","page":"Getting Started","title":"Getting Started","text":"To get help on specific functionality you can either look up the information here, or if you prefer you can make use of Julia's native doc-system. The following example shows how to get additional information on L1HingeLoss within Julia's REPL:","category":"page"},{"location":"introduction/gettingstarted/","page":"Getting Started","title":"Getting Started","text":"?L1HingeLoss","category":"page"},{"location":"introduction/gettingstarted/","page":"Getting Started","title":"Getting Started","text":"If you find yourself stuck or have other questions concerning the package you can find us on the Julia's Zulip chat or the Machine Learning domain on Discourse:","category":"page"},{"location":"introduction/gettingstarted/","page":"Getting Started","title":"Getting Started","text":"Machine Learning in Julia","category":"page"},{"location":"introduction/gettingstarted/","page":"Getting Started","title":"Getting Started","text":"If you encounter a bug or would like to participate in the further development of this package come find us on Github.","category":"page"},{"location":"introduction/gettingstarted/","page":"Getting Started","title":"Getting Started","text":"JuliaML/LossFunctions.jl","category":"page"},{"location":"acknowledgements/#Acknowledgements","page":"Acknowledgements","title":"Acknowledgements","text":"","category":"section"},{"location":"acknowledgements/","page":"Acknowledgements","title":"Acknowledgements","text":"The basic design of this package is heavily modelled after the loss-related definitions in [STEINWART2008].","category":"page"},{"location":"acknowledgements/","page":"Acknowledgements","title":"Acknowledgements","text":"We would also like to mention that some early inspiration was drawn from EmpiricalRisks.jl","category":"page"},{"location":"acknowledgements/#References","page":"Acknowledgements","title":"References","text":"","category":"section"},{"location":"acknowledgements/","page":"Acknowledgements","title":"Acknowledgements","text":"[STEINWART2008]: Steinwart, Ingo, and Andreas Christmann. \"Support vector machines\". Springer Science & Business Media, 2008.","category":"page"},{"location":"advanced/extend/","page":"Altering existing Losses","title":"Altering existing Losses","text":"DocTestSetup = quote\n    using LossFunctions\nend","category":"page"},{"location":"advanced/extend/#Altering-existing-Losses","page":"Altering existing Losses","title":"Altering existing Losses","text":"","category":"section"},{"location":"advanced/extend/","page":"Altering existing Losses","title":"Altering existing Losses","text":"There are situations in which one wants to work with slightly altered versions of specific loss functions. This package provides two generic ways to create such meta losses for specific families of loss functions.","category":"page"},{"location":"advanced/extend/","page":"Altering existing Losses","title":"Altering existing Losses","text":"Scaling a supervised loss by a constant real number. This is done at compile time and can in some situations even lead to simpler code (e.g. in the case of the derivative for a L2DistLoss)\nWeighting the classes of a margin-based loss differently in order to better deal with unbalanced binary classification problems.","category":"page"},{"location":"advanced/extend/#Scaling-a-Supervised-Loss","page":"Altering existing Losses","title":"Scaling a Supervised Loss","text":"","category":"section"},{"location":"advanced/extend/","page":"Altering existing Losses","title":"Altering existing Losses","text":"It is quite common in machine learning courses to define the least squares loss as frac12 (haty - y)^2, while this package implements that type of loss as an L_2 distance loss using (haty - y)^2, i.e. without the constant scale factor.","category":"page"},{"location":"advanced/extend/","page":"Altering existing Losses","title":"Altering existing Losses","text":"For situations in which one wants a scaled version of an existing loss type, we provide the concept of a scaled loss. The difference is literally only a constant real number that gets multiplied to the existing implementation of the loss function (and derivatives).","category":"page"},{"location":"advanced/extend/","page":"Altering existing Losses","title":"Altering existing Losses","text":"ScaledLoss","category":"page"},{"location":"advanced/extend/#LossFunctions.ScaledLoss","page":"Altering existing Losses","title":"LossFunctions.ScaledLoss","text":"ScaledLoss{L,K} <: SupervisedLoss\n\nCan be used to represent a K times scaled version of a given type of loss L.\n\n\n\n\n\n","category":"type"},{"location":"advanced/extend/","page":"Altering existing Losses","title":"Altering existing Losses","text":"julia> lsloss = 1/2 * L2DistLoss()\nScaledLoss{L2DistLoss, 0.5}(L2DistLoss())\n\njulia> L2DistLoss()(4.0, 0.0)\n16.0\n\njulia> lsloss(4.0, 0.0)\n8.0","category":"page"},{"location":"advanced/extend/","page":"Altering existing Losses","title":"Altering existing Losses","text":"As you have probably noticed, the constant scale factor gets promoted to a type-parameter. This can be quite an overhead when done on the fly every time the loss value is computed. To avoid this one can make use of Val to specify the scale factor in a type-stable manner.","category":"page"},{"location":"advanced/extend/","page":"Altering existing Losses","title":"Altering existing Losses","text":"julia> sl = ScaledLoss(L2DistLoss(), Val(0.5))\nScaledLoss{L2DistLoss, 0.5}(L2DistLoss())","category":"page"},{"location":"advanced/extend/","page":"Altering existing Losses","title":"Altering existing Losses","text":"Storing the scale factor as a type-parameter instead of a member variable has some nice advantages. It allows the compiler to do some quite convenient optimizations if possible. For example the compiler is able to figure out that the derivative simplifies for a scaled loss. This is accomplished using the power of @fastmath.","category":"page"},{"location":"advanced/extend/#Reweighting-a-Margin-Loss","page":"Altering existing Losses","title":"Reweighting a Margin Loss","text":"","category":"section"},{"location":"advanced/extend/","page":"Altering existing Losses","title":"Altering existing Losses","text":"It is not uncommon in classification scenarios to find yourself working with in-balanced data sets, where one class has much more observations than the other one. There are different strategies to deal with this kind of problem. The approach that this package provides is to weight the loss for the classes differently. This basically means that we penalize mistakes in one class more than mistakes in the other class. More specifically we scale the loss of the positive class by the weight-factor w and the loss of the negative class with 1-w.","category":"page"},{"location":"advanced/extend/","page":"Altering existing Losses","title":"Altering existing Losses","text":"if target > 0\n    w * loss(target, output)\nelse\n    (1-w) * loss(target, output)\nend","category":"page"},{"location":"advanced/extend/","page":"Altering existing Losses","title":"Altering existing Losses","text":"Instead of providing special functions to compute a class-weighted loss, we instead expose a generic way to create new weighted versions of already existing unweighted margin losses. This way, every existing subtype of MarginLoss can be re-weighted arbitrarily. Furthermore, it allows every algorithm that expects a binary loss to work with weighted binary losses as well.","category":"page"},{"location":"advanced/extend/","page":"Altering existing Losses","title":"Altering existing Losses","text":"WeightedMarginLoss","category":"page"},{"location":"advanced/extend/#LossFunctions.WeightedMarginLoss","page":"Altering existing Losses","title":"LossFunctions.WeightedMarginLoss","text":"WeightedMarginLoss{L,W} <: MarginLoss\n\nCan an be used to represent a re-weighted version of some type of binary loss L. The weight-factor W, which must be in [0, 1], denotes the relative weight of the positive class, while the relative weight of the negative class will be 1 - W.\n\n\n\n\n\n","category":"type"},{"location":"advanced/extend/","page":"Altering existing Losses","title":"Altering existing Losses","text":"julia> myloss = WeightedMarginLoss(HingeLoss(), 0.8)\nWeightedMarginLoss{L1HingeLoss, 0.8}(L1HingeLoss())\n\njulia> myloss(-4.0, 1.0) # positive class\n4.0\n\njulia> HingeLoss()(-4.0, 1.0)\n5.0\n\njulia> myloss(4.0, -1.0) # negative class\n0.9999999999999998\n\njulia> HingeLoss()(4.0, -1.0)\n5.0","category":"page"},{"location":"advanced/extend/","page":"Altering existing Losses","title":"Altering existing Losses","text":"Note that the scaled version of a margin-based loss does not anymore belong to the family of margin-based losses itself. In other words the resulting loss is neither a subtype of MarginLoss, nor of the original type of loss.","category":"page"},{"location":"advanced/extend/","page":"Altering existing Losses","title":"Altering existing Losses","text":"julia> typeof(myloss) <: MarginLoss\nfalse\n\njulia> typeof(myloss) <: HingeLoss\nfalse","category":"page"},{"location":"advanced/extend/","page":"Altering existing Losses","title":"Altering existing Losses","text":"Similar to scaled losses, the constant weight factor gets promoted to a type-parameter. This can be quite an overhead when done on the fly every time the loss value is computed. To avoid this one can make use of Val to specify the scale factor in a type-stable manner.","category":"page"},{"location":"advanced/extend/","page":"Altering existing Losses","title":"Altering existing Losses","text":"julia> WeightedMarginLoss(HingeLoss(), Val(0.8))\nWeightedMarginLoss{L1HingeLoss, 0.8}(L1HingeLoss())","category":"page"},{"location":"losses/distance/#Distance-based-Losses","page":"Distance-based Losses","title":"Distance-based Losses","text":"","category":"section"},{"location":"losses/distance/","page":"Distance-based Losses","title":"Distance-based Losses","text":"Loss functions that belong to the category \"distance-based\" are primarily used in regression problems. They utilize the numeric difference between the predicted output and the true target as a proxy variable to quantify the quality of individual predictions.","category":"page"},{"location":"losses/distance/","page":"Distance-based Losses","title":"Distance-based Losses","text":"This section lists all the subtypes of DistanceLoss that are implemented in this package.","category":"page"},{"location":"losses/distance/#LPDistLoss","page":"Distance-based Losses","title":"LPDistLoss","text":"","category":"section"},{"location":"losses/distance/","page":"Distance-based Losses","title":"Distance-based Losses","text":"LPDistLoss","category":"page"},{"location":"losses/distance/#LossFunctions.LPDistLoss","page":"Distance-based Losses","title":"LossFunctions.LPDistLoss","text":"LPDistLoss{P} <: DistanceLoss\n\nThe P-th power absolute distance loss. It is Lipschitz continuous iff P == 1, convex if and only if P >= 1, and strictly convex iff P > 1.\n\nL(r) = r^P\n\n\n\n","category":"type"},{"location":"losses/distance/#L1DistLoss","page":"Distance-based Losses","title":"L1DistLoss","text":"","category":"section"},{"location":"losses/distance/","page":"Distance-based Losses","title":"Distance-based Losses","text":"L1DistLoss","category":"page"},{"location":"losses/distance/#LossFunctions.L1DistLoss","page":"Distance-based Losses","title":"LossFunctions.L1DistLoss","text":"L1DistLoss <: DistanceLoss\n\nThe absolute distance loss. Special case of the LPDistLoss with P=1. It is Lipschitz continuous and convex, but not strictly convex.\n\nL(r) = r\n\n\n\n              Lossfunction                     Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    3 │\\.                     ./│    1 │            ┌------------│\n      │ '\\.                 ./' │      │            |            │\n      │   \\.               ./   │      │            |            │\n      │    '\\.           ./'    │      │_           |           _│\n    L │      \\.         ./      │   L' │            |            │\n      │       '\\.     ./'       │      │            |            │\n      │         \\.   ./         │      │            |            │\n    0 │          '\\./'          │   -1 │------------┘            │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -3                        3      -3                        3\n                 ŷ - y                            ŷ - y\n\n\n\n","category":"type"},{"location":"losses/distance/#L2DistLoss","page":"Distance-based Losses","title":"L2DistLoss","text":"","category":"section"},{"location":"losses/distance/","page":"Distance-based Losses","title":"Distance-based Losses","text":"L2DistLoss","category":"page"},{"location":"losses/distance/#LossFunctions.L2DistLoss","page":"Distance-based Losses","title":"LossFunctions.L2DistLoss","text":"L2DistLoss <: DistanceLoss\n\nThe least squares loss. Special case of the LPDistLoss with P=2. It is strictly convex.\n\nL(r) = r^2\n\n\n\n              Lossfunction                     Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    9 │\\                       /│    3 │                   .r/   │\n      │\".                     .\"│      │                 .r'     │\n      │ \".                   .\" │      │              _./'       │\n      │  \".                 .\"  │      │_           .r/         _│\n    L │   \".               .\"   │   L' │         _:/'            │\n      │    '\\.           ./'    │      │       .r'               │\n      │      \\.         ./      │      │     .r'                 │\n    0 │        \"-.___.-\"        │   -3 │  _/r'                   │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -3                        3      -2                        2\n                 ŷ - y                            ŷ - y\n\n\n\n","category":"type"},{"location":"losses/distance/#LogitDistLoss","page":"Distance-based Losses","title":"LogitDistLoss","text":"","category":"section"},{"location":"losses/distance/","page":"Distance-based Losses","title":"Distance-based Losses","text":"LogitDistLoss","category":"page"},{"location":"losses/distance/#LossFunctions.LogitDistLoss","page":"Distance-based Losses","title":"LossFunctions.LogitDistLoss","text":"LogitDistLoss <: DistanceLoss\n\nThe distance-based logistic loss for regression. It is strictly convex and Lipschitz continuous.\n\nL(r) = - ln frac4 e^r(1 + e^r)^2\n\n\n\n              Lossfunction                     Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    2 │                         │    1 │                   _--'''│\n      │\\                       /│      │                ./'      │\n      │ \\.                   ./ │      │              ./         │\n      │  '.                 .'  │      │_           ./          _│\n    L │   '.               .'   │   L' │           ./            │\n      │     \\.           ./     │      │         ./              │\n      │      '.         .'      │      │       ./                │\n    0 │        '-.___.-'        │   -1 │___.-''                  │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -3                        3      -4                        4\n                 ŷ - y                            ŷ - y\n\n\n\n","category":"type"},{"location":"losses/distance/#HuberLoss","page":"Distance-based Losses","title":"HuberLoss","text":"","category":"section"},{"location":"losses/distance/","page":"Distance-based Losses","title":"Distance-based Losses","text":"HuberLoss","category":"page"},{"location":"losses/distance/#LossFunctions.HuberLoss","page":"Distance-based Losses","title":"LossFunctions.HuberLoss","text":"HuberLoss <: DistanceLoss\n\nLoss function commonly used for robustness to outliers. For large values of d it becomes close to the L1DistLoss, while for small values of d it resembles the L2DistLoss. It is Lipschitz continuous and convex, but not strictly convex.\n\nL(r) = begincases fracr^22  quad textif   r  le alpha  alpha  r  - fracalpha^32  quad textotherwise endcases\n\n\n\n              Lossfunction (d=1)               Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    2 │                         │    1 │                .+-------│\n      │                         │      │              ./'        │\n      │\\.                     ./│      │             ./          │\n      │ '.                   .' │      │_           ./          _│\n    L │   \\.               ./   │   L' │           /'            │\n      │     \\.           ./     │      │          /'             │\n      │      '.         .'      │      │        ./'              │\n    0 │        '-.___.-'        │   -1 │-------+'                │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -2                        2      -2                        2\n                 ŷ - y                            ŷ - y\n\n\n\n","category":"type"},{"location":"losses/distance/#L1EpsilonInsLoss","page":"Distance-based Losses","title":"L1EpsilonInsLoss","text":"","category":"section"},{"location":"losses/distance/","page":"Distance-based Losses","title":"Distance-based Losses","text":"L1EpsilonInsLoss","category":"page"},{"location":"losses/distance/#LossFunctions.L1EpsilonInsLoss","page":"Distance-based Losses","title":"LossFunctions.L1EpsilonInsLoss","text":"L1EpsilonInsLoss <: DistanceLoss\n\nThe ϵ-insensitive loss. Typically used in linear support vector regression. It ignores deviances smaller than ϵ, but penalizes larger deviances linarily. It is Lipschitz continuous and convex, but not strictly convex.\n\nL(r) = max  0  r  - epsilon \n\n\n\n              Lossfunction (ϵ=1)               Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    2 │\\                       /│    1 │                  ┌------│\n      │ \\                     / │      │                  |      │\n      │  \\                   /  │      │                  |      │\n      │   \\                 /   │      │_      ___________!     _│\n    L │    \\               /    │   L' │      |                  │\n      │     \\             /     │      │      |                  │\n      │      \\           /      │      │      |                  │\n    0 │       \\_________/       │   -1 │------┘                  │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -3                        3      -2                        2\n                 ŷ - y                            ŷ - y\n\n\n\n","category":"type"},{"location":"losses/distance/#L2EpsilonInsLoss","page":"Distance-based Losses","title":"L2EpsilonInsLoss","text":"","category":"section"},{"location":"losses/distance/","page":"Distance-based Losses","title":"Distance-based Losses","text":"L2EpsilonInsLoss","category":"page"},{"location":"losses/distance/#LossFunctions.L2EpsilonInsLoss","page":"Distance-based Losses","title":"LossFunctions.L2EpsilonInsLoss","text":"L2EpsilonInsLoss <: DistanceLoss\n\nThe quadratic ϵ-insensitive loss. Typically used in linear support vector regression. It ignores deviances smaller than ϵ, but penalizes larger deviances quadratically. It is convex, but not strictly convex.\n\nL(r) = max  0  r  - epsilon ^2\n\n\n\n              Lossfunction (ϵ=0.5)             Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    8 │                         │    1 │                  /      │\n      │:                       :│      │                 /       │\n      │'.                     .'│      │                /        │\n      │ \\.                   ./ │      │_         _____/        _│\n    L │  \\.                 ./  │   L' │         /               │\n      │   \\.               ./   │      │        /                │\n      │    '\\.           ./'    │      │       /                 │\n    0 │      '-._______.-'      │   -1 │      /                  │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -3                        3      -2                        2\n                 ŷ - y                            ŷ - y\n\n\n\n","category":"type"},{"location":"losses/distance/#PeriodicLoss","page":"Distance-based Losses","title":"PeriodicLoss","text":"","category":"section"},{"location":"losses/distance/","page":"Distance-based Losses","title":"Distance-based Losses","text":"PeriodicLoss","category":"page"},{"location":"losses/distance/#LossFunctions.PeriodicLoss","page":"Distance-based Losses","title":"LossFunctions.PeriodicLoss","text":"PeriodicLoss <: DistanceLoss\n\nMeasures distance on a circle of specified circumference c.\n\nL(r) = 1 - cos left( frac2 r pic right)\n\n\n\n","category":"type"},{"location":"losses/distance/#QuantileLoss","page":"Distance-based Losses","title":"QuantileLoss","text":"","category":"section"},{"location":"losses/distance/","page":"Distance-based Losses","title":"Distance-based Losses","text":"QuantileLoss","category":"page"},{"location":"losses/distance/#LossFunctions.QuantileLoss","page":"Distance-based Losses","title":"LossFunctions.QuantileLoss","text":"QuantileLoss <: DistanceLoss\n\nThe distance-based quantile loss, also known as pinball loss, can be used to estimate conditional τ-quantiles. It is Lipschitz continuous and convex, but not strictly convex. Furthermore it is symmetric if and only if τ = 1/2.\n\nL(r) = begincases -left( 1 - tau  right) r  quad textif  r  0  tau r  quad textif  r ge 0  endcases\n\n\n\n              Lossfunction (τ=0.7)             Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    2 │'\\                       │  0.3 │            ┌------------│\n      │  \\.                     │      │            |            │\n      │   '\\                    │      │_           |           _│\n      │     \\.                  │      │            |            │\n    L │      '\\              ._-│   L' │            |            │\n      │        \\.         ..-'  │      │            |            │\n      │         '.     _r/'     │      │            |            │\n    0 │           '_./'         │ -0.7 │------------┘            │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -3                        3      -3                        3\n                 ŷ - y                            ŷ - y\n\n\n\n","category":"type"},{"location":"losses/distance/#LogCoshLoss","page":"Distance-based Losses","title":"LogCoshLoss","text":"","category":"section"},{"location":"losses/distance/","page":"Distance-based Losses","title":"Distance-based Losses","text":"LogCoshLoss","category":"page"},{"location":"losses/distance/#LossFunctions.LogCoshLoss","page":"Distance-based Losses","title":"LossFunctions.LogCoshLoss","text":"LogCoshLoss <: DistanceLoss\n\nThe log cosh loss is twice differentiable, strongly convex, Lipschitz continous function.\n\nL(r) = log ( cosh ( x ))\n\n\n\n           Lossfunction                     Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n  2.5 │\\                       /│    1 │                 .-------│\n      │\".                     .\"│      │                |        │\n      │ \".                   .\" │      │               /         │\n      │  \".                 .\"  │      │_           . \"         _│\n    L │   \".               .\"   │   L' │         /\"              │\n      │    '\\.           ./'    │      │       .\"                │\n      │      \\.         ./      │      │       |                 │\n    0 │        \"-. _ .-\"        │   -1 │------\"                  │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -3                        3      -3                        3\n                 ŷ - y                            ŷ - y\n\n\n\n","category":"type"},{"location":"losses/distance/","page":"Distance-based Losses","title":"Distance-based Losses","text":"note: Note\nYou may note that our definition of the QuantileLoss looks different to what one usually sees in other literature. The reason is that we have to correct for the fact that in our case r = haty - y instead of r_textrmusual = y - haty, which means that our definition relates to that in the manner of r = -1 * r_textrmusual.","category":"page"},{"location":"losses/distance/","page":"Distance-based Losses","title":"Distance-based Losses","text":"</div>","category":"page"},{"location":"losses/margin/#Margin-based-Losses","page":"Margin-based Losses","title":"Margin-based Losses","text":"","category":"section"},{"location":"losses/margin/","page":"Margin-based Losses","title":"Margin-based Losses","text":"Margin-based loss functions are particularly useful for binary classification. In contrast to the distance-based losses, these do not care about the difference between true target and prediction. Instead they penalize predictions based on how well they agree with the sign of the target.","category":"page"},{"location":"losses/margin/","page":"Margin-based Losses","title":"Margin-based Losses","text":"This section lists all the subtypes of MarginLoss that are implemented in this package.","category":"page"},{"location":"losses/margin/#ZeroOneLoss","page":"Margin-based Losses","title":"ZeroOneLoss","text":"","category":"section"},{"location":"losses/margin/","page":"Margin-based Losses","title":"Margin-based Losses","text":"ZeroOneLoss","category":"page"},{"location":"losses/margin/#LossFunctions.ZeroOneLoss","page":"Margin-based Losses","title":"LossFunctions.ZeroOneLoss","text":"ZeroOneLoss <: MarginLoss\n\nThe classical classification loss. It penalizes every misclassified observation with a loss of 1 while every correctly classified observation has a loss of 0. It is not convex nor continuous and thus seldom used directly. Instead one usually works with some classification-calibrated surrogate loss, such as L1HingeLoss.\n\nL(a) = begincases 1  quad textif  a  0  0  quad textif  a = 0 endcases\n\n\n\n              Lossfunction                     Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    1 │------------┐            │    1 │                         │\n      │            |            │      │                         │\n      │            |            │      │                         │\n      │            |            │      │_________________________│\n      │            |            │      │                         │\n      │            |            │      │                         │\n      │            |            │      │                         │\n    0 │            └------------│   -1 │                         │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -2                        2      -2                        2\n                y * h(x)                         y * h(x)\n\n\n\n","category":"type"},{"location":"losses/margin/#PerceptronLoss","page":"Margin-based Losses","title":"PerceptronLoss","text":"","category":"section"},{"location":"losses/margin/","page":"Margin-based Losses","title":"Margin-based Losses","text":"PerceptronLoss","category":"page"},{"location":"losses/margin/#LossFunctions.PerceptronLoss","page":"Margin-based Losses","title":"LossFunctions.PerceptronLoss","text":"PerceptronLoss <: MarginLoss\n\nThe perceptron loss linearly penalizes every prediction where the resulting agreement <= 0. It is Lipschitz continuous and convex, but not strictly convex.\n\nL(a) = max  0 -a \n\n\n\n              Lossfunction                     Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    2 │\\.                       │    0 │            ┌------------│\n      │ '..                     │      │            |            │\n      │   \\.                    │      │            |            │\n      │     '.                  │      │            |            │\n    L │      '.                 │   L' │            |            │\n      │        \\.               │      │            |            │\n      │         '.              │      │            |            │\n    0 │           \\.____________│   -1 │------------┘            │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -2                        2      -2                        2\n                 y ⋅ ŷ                            y ⋅ ŷ\n\n\n\n","category":"type"},{"location":"losses/margin/#L1HingeLoss","page":"Margin-based Losses","title":"L1HingeLoss","text":"","category":"section"},{"location":"losses/margin/","page":"Margin-based Losses","title":"Margin-based Losses","text":"L1HingeLoss","category":"page"},{"location":"losses/margin/#LossFunctions.L1HingeLoss","page":"Margin-based Losses","title":"LossFunctions.L1HingeLoss","text":"L1HingeLoss <: MarginLoss\n\nThe hinge loss linearly penalizes every predicition where the resulting agreement < 1 . It is Lipschitz continuous and convex, but not strictly convex.\n\nL(a) = max  0 1 - a \n\n\n\n              Lossfunction                     Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    3 │'\\.                      │    0 │                  ┌------│\n      │  ''_                    │      │                  |      │\n      │     \\.                  │      │                  |      │\n      │       '.                │      │                  |      │\n    L │         ''_             │   L' │                  |      │\n      │            \\.           │      │                  |      │\n      │              '.         │      │                  |      │\n    0 │                ''_______│   -1 │------------------┘      │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -2                        2      -2                        2\n                 y ⋅ ŷ                            y ⋅ ŷ\n\n\n\n","category":"type"},{"location":"losses/margin/#SmoothedL1HingeLoss","page":"Margin-based Losses","title":"SmoothedL1HingeLoss","text":"","category":"section"},{"location":"losses/margin/","page":"Margin-based Losses","title":"Margin-based Losses","text":"SmoothedL1HingeLoss","category":"page"},{"location":"losses/margin/#LossFunctions.SmoothedL1HingeLoss","page":"Margin-based Losses","title":"LossFunctions.SmoothedL1HingeLoss","text":"SmoothedL1HingeLoss <: MarginLoss\n\nAs the name suggests a smoothed version of the L1 hinge loss. It is Lipschitz continuous and convex, but not strictly convex.\n\nL(a) = begincases frac05gamma cdot max  0 1 - a  ^2  quad textif  a ge 1 - gamma  1 - fracgamma2 - a  quad textotherwise endcases\n\n\n\n              Lossfunction (γ=2)               Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    2 │\\.                       │    0 │                 ,r------│\n      │ '.                      │      │               ./'       │\n      │   \\.                    │      │              ,/         │\n      │     '.                  │      │            ./'          │\n    L │      '.                 │   L' │           ,'            │\n      │        \\.               │      │         ,/              │\n      │          ',             │      │       ./'               │\n    0 │            '*-._________│   -1 │______./                 │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -2                        2      -2                        2\n                 y ⋅ ŷ                            y ⋅ ŷ\n\n\n\n","category":"type"},{"location":"losses/margin/#ModifiedHuberLoss","page":"Margin-based Losses","title":"ModifiedHuberLoss","text":"","category":"section"},{"location":"losses/margin/","page":"Margin-based Losses","title":"Margin-based Losses","text":"ModifiedHuberLoss","category":"page"},{"location":"losses/margin/#LossFunctions.ModifiedHuberLoss","page":"Margin-based Losses","title":"LossFunctions.ModifiedHuberLoss","text":"ModifiedHuberLoss <: MarginLoss\n\nA special (4 times scaled) case of the SmoothedL1HingeLoss with γ=2. It is Lipschitz continuous and convex, but not strictly convex.\n\nL(a) = begincases max  0 1 - a  ^2  quad textif  a ge -1  - 4 a  quad textotherwise endcases\n\n\n\n              Lossfunction                     Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    5 │    '.                   │    0 │                .+-------│\n      │     '.                  │      │              ./'        │\n      │      '\\                 │      │             ,/          │\n      │        \\                │      │           ,/            │\n    L │         '.              │   L' │         ./              │\n      │          '.             │      │       ./'               │\n      │            \\.           │      │______/'                 │\n    0 │              '-.________│   -5 │                         │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -2                        2      -2                        2\n                 y ⋅ ŷ                            y ⋅ ŷ\n\n\n\n","category":"type"},{"location":"losses/margin/#DWDMarginLoss","page":"Margin-based Losses","title":"DWDMarginLoss","text":"","category":"section"},{"location":"losses/margin/","page":"Margin-based Losses","title":"Margin-based Losses","text":"DWDMarginLoss","category":"page"},{"location":"losses/margin/#LossFunctions.DWDMarginLoss","page":"Margin-based Losses","title":"LossFunctions.DWDMarginLoss","text":"DWDMarginLoss <: MarginLoss\n\nThe distance weighted discrimination margin loss. It is a differentiable generalization of the L1HingeLoss that is different than the SmoothedL1HingeLoss. It is Lipschitz continuous and convex, but not strictly convex.\n\nL(a) = begincases 1 - a  quad textif  a ge fracqq+1  frac1a^q fracq^q(q+1)^q+1  quad textotherwise endcases\n\n\n\n              Lossfunction (q=1)               Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    2 │      \".                 │    0 │                     ._r-│\n      │        \\.               │      │                   ./    │\n      │         ',              │      │                 ./      │\n      │           \\.            │      │                 /       │\n    L │            \"\\.          │   L' │                .        │\n      │              \\.         │      │                /        │\n      │               \":__      │      │               ;         │\n    0 │                   '\"\"---│   -1 │---------------┘         │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -2                        2      -2                        2\n                 y ⋅ ŷ                            y ⋅ ŷ\n\n\n\n","category":"type"},{"location":"losses/margin/#L2MarginLoss","page":"Margin-based Losses","title":"L2MarginLoss","text":"","category":"section"},{"location":"losses/margin/","page":"Margin-based Losses","title":"Margin-based Losses","text":"L2MarginLoss","category":"page"},{"location":"losses/margin/#LossFunctions.L2MarginLoss","page":"Margin-based Losses","title":"LossFunctions.L2MarginLoss","text":"L2MarginLoss <: MarginLoss\n\nThe margin-based least-squares loss for classification, which penalizes every prediction where agreement != 1 quadratically. It is locally Lipschitz continuous and strongly convex.\n\nL(a) = left( 1 - a right)^2\n\n\n\n              Lossfunction                     Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    5 │     .                   │    2 │                       ,r│\n      │     '.                  │      │                     ,/  │\n      │      '\\                 │      │                   ,/    │\n      │        \\                │      ├                 ,/      ┤\n    L │         '.              │   L' │               ./        │\n      │          '.             │      │             ./          │\n      │            \\.          .│      │           ./            │\n    0 │              '-.____.-' │   -3 │         ./              │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -2                        2      -2                        2\n                 y ⋅ ŷ                            y ⋅ ŷ\n\n\n\n","category":"type"},{"location":"losses/margin/#L2HingeLoss","page":"Margin-based Losses","title":"L2HingeLoss","text":"","category":"section"},{"location":"losses/margin/","page":"Margin-based Losses","title":"Margin-based Losses","text":"L2HingeLoss","category":"page"},{"location":"losses/margin/#LossFunctions.L2HingeLoss","page":"Margin-based Losses","title":"LossFunctions.L2HingeLoss","text":"L2HingeLoss <: MarginLoss\n\nThe truncated least squares loss quadratically penalizes every predicition where the resulting agreement < 1. It is locally Lipschitz continuous and convex, but not strictly convex.\n\nL(a) = max  0 1 - a ^2\n\n\n\n              Lossfunction                     Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    5 │     .                   │    0 │                 ,r------│\n      │     '.                  │      │               ,/        │\n      │      '\\                 │      │             ,/          │\n      │        \\                │      │           ,/            │\n    L │         '.              │   L' │         ./              │\n      │          '.             │      │       ./                │\n      │            \\.           │      │     ./                  │\n    0 │              '-.________│   -5 │   ./                    │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -2                        2      -2                        2\n                 y ⋅ ŷ                            y ⋅ ŷ\n\n\n\n","category":"type"},{"location":"losses/margin/#LogitMarginLoss","page":"Margin-based Losses","title":"LogitMarginLoss","text":"","category":"section"},{"location":"losses/margin/","page":"Margin-based Losses","title":"Margin-based Losses","text":"LogitMarginLoss","category":"page"},{"location":"losses/margin/#LossFunctions.LogitMarginLoss","page":"Margin-based Losses","title":"LossFunctions.LogitMarginLoss","text":"LogitMarginLoss <: MarginLoss\n\nThe margin version of the logistic loss. It is infinitely many times differentiable, strictly convex, and Lipschitz continuous.\n\nL(a) = ln (1 + e^-a)\n\n\n\n              Lossfunction                     Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    2 │ \\.                      │    0 │                  ._--/\"\"│\n      │   \\.                    │      │               ../'      │\n      │     \\.                  │      │              ./         │\n      │       \\..               │      │            ./'          │\n    L │         '-_             │   L' │          .,'            │\n      │            '-_          │      │         ./              │\n      │               '\\-._     │      │      .,/'               │\n    0 │                    '\"\"*-│   -1 │__.--''                  │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -2                        2      -4                        4\n                 y ⋅ ŷ                            y ⋅ ŷ\n\n\n\n","category":"type"},{"location":"losses/margin/#ExpLoss","page":"Margin-based Losses","title":"ExpLoss","text":"","category":"section"},{"location":"losses/margin/","page":"Margin-based Losses","title":"Margin-based Losses","text":"ExpLoss","category":"page"},{"location":"losses/margin/#LossFunctions.ExpLoss","page":"Margin-based Losses","title":"LossFunctions.ExpLoss","text":"ExpLoss <: MarginLoss\n\nThe margin-based exponential loss for classification, which penalizes every prediction exponentially. It is infinitely many times differentiable, locally Lipschitz continuous and strictly convex, but not clipable.\n\nL(a) = e^-a\n\n\n\n              Lossfunction                     Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    5 │  \\.                     │    0 │               _,,---:'\"\"│\n      │   l                     │      │           _r/\"'         │\n      │    l.                   │      │        .r/'             │\n      │     \":                  │      │      .r'                │\n    L │       \\.                │   L' │     ./                  │\n      │        \"\\..             │      │    .'                   │\n      │           '\":,_         │      │   ,'                    │\n    0 │                \"\"---:.__│   -5 │  ./                     │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -2                        2      -2                        2\n                 y ⋅ ŷ                            y ⋅ ŷ\n\n\n\n","category":"type"},{"location":"losses/margin/#SigmoidLoss","page":"Margin-based Losses","title":"SigmoidLoss","text":"","category":"section"},{"location":"losses/margin/","page":"Margin-based Losses","title":"Margin-based Losses","text":"SigmoidLoss","category":"page"},{"location":"losses/margin/#LossFunctions.SigmoidLoss","page":"Margin-based Losses","title":"LossFunctions.SigmoidLoss","text":"SigmoidLoss <: MarginLoss\n\nContinuous loss which penalizes every prediction with a loss within in the range (0,2). It is infinitely many times differentiable, Lipschitz continuous but nonconvex.\n\nL(a) = 1 - tanh(a)\n\n\n\n              Lossfunction                     Derivative\n      ┌────────────┬────────────┐      ┌────────────┬────────────┐\n    2 │\"\"'--,.                  │    0 │..                     ..│\n      │      '\\.                │      │ \"\\.                 ./\" │\n      │         '.              │      │    ',             ,'    │\n      │           \\.            │      │      \\           /      │\n    L │            \"\\.          │   L' │       \\         /       │\n      │              \\.         │      │        \\.     ./        │\n      │                \\,       │      │         \\.   ./         │\n    0 │                  '\"-:.__│   -1 │          ',_,'          │\n      └────────────┴────────────┘      └────────────┴────────────┘\n      -2                        2      -2                        2\n                 y ⋅ ŷ                            y ⋅ ŷ\n\n\n\n","category":"type"},{"location":"losses/margin/","page":"Margin-based Losses","title":"Margin-based Losses","text":"</div>","category":"page"},{"location":"introduction/motivation/#Background-and-Motivation","page":"Background and Motivation","title":"Background and Motivation","text":"","category":"section"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"In this section we will discuss the concept \"loss function\" in more detail. We will start by introducing some terminology and definitions. However, please note that we won't attempt to give a complete treatment of loss functions and the math involved (unlike a book or a lecture could do). So this section won't be a substitution for proper literature on the topic. While we will try to cover all the basics necessary to get a decent intuition of the ideas involved, we do assume basic knowledge about Machine Learning.","category":"page"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"warning: Warning\nThis section and its sub-sections serve solely as to explain the underlying theory and concepts and further to motivate the solution provided by this package. As such, this section is not intended as a guide on how to apply this package.","category":"page"},{"location":"introduction/motivation/#Terminology","page":"Background and Motivation","title":"Terminology","text":"","category":"section"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"To start off, let us go over some basic terminology. In Machine Learning (ML) we are primarily interested in automatically learning meaningful patterns from data. For our purposes it suffices to say that in ML we try to teach the computer to solve a task by induction rather than by definition. This package is primarily concerned with the subset of Machine Learning that falls under the umbrella of Supervised Learning. There we are interested in teaching the computer to predict a specific output for some given input. In contrast to unsupervised learning the teaching process here involves showing the computer what the predicted output is supposed to be; i.e. the \"true answer\" if you will.","category":"page"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"How is this relevant for this package? Well, it implies that we require some meaningful way to show the true answers to the computer so that it can learn from \"seeing\" them. More importantly, we have to somehow put the true answer into relation to what the computer currently predicts the answer should be. This would provide the basic information needed for the computer to be able to improve; that is what loss functions are for.","category":"page"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"When we say we want our computer to learn something that is able to make predictions, we are talking about a prediction function, denoted as h and sometimes called \"fitted hypothesis\", or \"fitted model\". Note that we will avoid the term hypothesis for the simple reason that it is widely used in statistics for something completely different. We don't consider a prediction function as the same thing as a prediction model, because we think of a prediction model as a family of prediction functions. What that boils down to is that the prediction model represents the set of possible prediction functions, while the final prediction function is the chosen function that best solves the prediction problem. So in a way a prediction model can be thought of as the manifestation of our assumptions about the problem, because it restricts the solution to a specific family of functions. For example a linear prediction model for two features represents all possible linear functions that have two coefficients. A prediction function would in that scenario be a concrete linear function with a particular fixed set of coefficients.","category":"page"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"The purpose of a prediction function is to take some input and produce a corresponding output. That output should be as faithful as possible to the true answer. In the context of this package we will refer to the \"true answer\" as the true target, or short \"target\". During training, and only during training, inputs and targets can both be considered as part of our data set. We say \"only during training\" because in a production setting we don't actually have the targets available to us (otherwise there would be no prediction problem to solve in the first place). In essence we can think of our data as two entities with a 1-to-1 connection in each observation, the inputs, which we call features, and the corresponding desired outputs, which we call true targets.","category":"page"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"Let us be a little more concrete with the two terms we really care about in this package.","category":"page"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"True Targets:\nA true target (singular) represents the \"desired\" output for the input features of a single observation. The targets are often referred to as \"ground truth\" and we will denote a single target as y in Y. While y can be a scalar or some array, the key is that it represents the target of a single observation. When we talk about an array (e.g. a vector) of multiple targets, we will print it in bold as mathbfy. What the set Y is will depend on the subdomain of supervised learning that you are working in.\nReal-valued Regression: Y subseteq mathbbR.\nMultioutput Regression: Y subseteq mathbbR^k.\nMargin-based Classification: Y = 1-1.\nProbabilistic Classification: Y = 10.\nMulticlass Classification: Y = 12dotsk.\nSee MLLabelUtils for more information on classification targets.\nPredicted Outputs:\nA predicted output (singular) is the result of our prediction function given the features of some observation. We will denote a single output as haty in mathbbR (pronounced as \"why hat\"). When we talk about an array of outputs for multiple observations, we will print it in bold as mathbfhaty. Note something unintuitive but important: The variables y and haty don't have to be of the same set. Even in a classification setting where y in 1-1, it is typical that haty in mathbbR.\nThe fact that in classification the predictions can be fundamentally different than the targets is important to know. The reason for restricting the targets to specific numbers when doing classification is mathematical convenience for loss functions. So loss functions have this knowledge build in.","category":"page"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"In a classification setting, the predicted outputs and the true targets are usually of different form and type. For example, in margin-based classification it could be the case that the target y=-1 and the predicted output haty = -1000. It would seem that the prediction is not really reflecting the target properly, but in this case we would actually have a perfectly correct prediction. This is because in margin-based classification the main thing that matters about the predicted output is that the sign agrees with the true target.","category":"page"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"Even though we talked about prediction functions and features, we will see that for computing loss functions all we really care about are the true targets and the predicted outputs, regardless of how the outputs were produced.","category":"page"},{"location":"introduction/motivation/#Definitions","page":"Background and Motivation","title":"Definitions","text":"","category":"section"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"We base most of our definitions on the work presented in [STEINWART2008]. Note, however, that we will adapt or simplify in places at our discretion. We do this in situations where it makes sense to us considering the scope of this package or because of implementation details.","category":"page"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"Let us again consider the term prediction function. More formally, a prediction function h is a function that maps an input from the feature space X to the real numbers mathbbR. So invoking h with some features x in X will produce the prediction haty in mathbbR.","category":"page"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"h  X rightarrow mathbbR","category":"page"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"This resulting prediction haty is what we want to compare to the target y in order to asses how bad the prediction is. The function we use for such an assessment will be of a family of functions we refer to as supervised losses. We think of a supervised loss as a function of two parameters, the true target y in Y and the predicted output haty in mathbbR. The result of computing such a loss will be a non-negative real number. The larger the value of the loss, the worse the prediction.","category":"page"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"L  mathbbR times Y rightarrow 0infty)","category":"page"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"Note a few interesting things about supervised loss functions.","category":"page"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"The absolute value of a loss is often (but not always) meaningless and doesn't offer itself to a useful interpretation. What we usually care about is that the loss is as small as it can be.\nIn general the loss function we use is not the function we are actually interested in minimizing. Instead we are minimizing what is referred to as a \"surrogate\". For binary classification for example we are really interested in minimizing the ZeroOne loss (which simply counts the number of misclassified predictions). However, that loss is difficult to minimize given that it is not convex nor continuous. That is why we use other loss functions, such as the hinge loss or logistic loss. Those losses are \"classification calibrated\", which basically means they are good enough surrogates to solve the same problem. Additionally, surrogate losses tend to have other nice properties.\nFor classification it does not need to be the case that a \"correct\" prediction has a loss of zero. In fact some classification calibrated losses are never truly zero.","category":"page"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"There are two sub-families of supervised loss-functions that are of particular interest, namely margin-based losses and distance-based losses. These two categories of loss functions are especially useful for the two basic sub-domains of supervised learning: Classification and Regression.","category":"page"},{"location":"introduction/motivation/#Margin-based-Losses-for-(Binary)-Classification","page":"Background and Motivation","title":"Margin-based Losses for (Binary) Classification","text":"","category":"section"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"Margin-based losses are mainly utilized for binary classification problems where the goal is to predict a categorical value. They assume that the set of targets Y is restricted to Y = 1-1. These two possible values for the target denote the positive class in the case of y = 1, and the negative class in the case of y = -1. In contrast to other formalism, they do not natively provide probabilities as output.","category":"page"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"More formally, we call a supervised loss function L  mathbbR times Y rightarrow 0 infty) margin-based if there exists a representing function psi  mathbbR rightarrow 0 infty) such that","category":"page"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"L(haty y) = psi (y cdot haty)  qquad  y in Y haty in mathbbR","category":"page"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"note: Note\nThroughout the codebase we refer to the result of y cdot haty as agreement. The discussion that lead to this convention can be found issue #9","category":"page"},{"location":"introduction/motivation/#Distance-based-Losses-for-Regression","page":"Background and Motivation","title":"Distance-based Losses for Regression","text":"","category":"section"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"Distance-based losses are usually used in regression settings where the goal is to predict some real valued variable. The goal there is that the prediction is as close as possible to the true target. In such a scenario it is quite sensible to penalize the distance between the prediction and the target in some way.","category":"page"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"More formally, a supervised loss function L  mathbbR times Y rightarrow 0 infty) is said to be distance-based, if there exists a representing function psi  mathbbR rightarrow 0 infty) satisfying psi (0) = 0 and","category":"page"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"L(haty y) = psi (haty - y)  qquad  y in Y haty in mathbbR","category":"page"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"note: Note\nIn the literature that this package is partially based on, the convention for the distance-based losses is that r = y - haty (see [STEINWART2008] p. 38). We chose to diverge from this definition because it would force a difference of the sign between the results for the unary and the binary version of the derivative. That difference would be a introduced by the chain rule, since the inner derivative would result in fracpartialpartial haty (y - haty) = -1.","category":"page"},{"location":"introduction/motivation/#Alternative-Viewpoints","page":"Background and Motivation","title":"Alternative Viewpoints","text":"","category":"section"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"While the term \"loss function\" is usually used in the same context throughout the literature, the specifics differ from one textbook to another. For that reason we would like to mention alternative definitions of what a \"loss function\" is. Note that we will only give a partial and thus very simplified description of these. Please refer to the listed sources for more specifics.","category":"page"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"In [SHALEV2014] the authors consider a loss function as a higher-order function of two parameters, a prediction model and an observation tuple. So in that definition a loss function and the prediction function are tightly coupled. This way of thinking about it makes a lot of sense, considering the process of how a prediction model is usually fit to the data. For gradient descent to do its job it needs the, well, gradient of the empirical risk. This gradient is computed using the chain rule for the inner loss and the prediction model. If one views the loss and the prediction model as one entity, then the gradient can sometimes be simplified immensely. That said, we chose to not follow this school of thought, because from a software-engineering standpoint it made more sense to us to have small modular pieces. So in our implementation the loss functions don't need to know that prediction functions even exist. This makes the package easier to maintain, test, and reason with. Given Julia's ability for multiple dispatch we don't even lose the ability to simplify the gradient if need be.","category":"page"},{"location":"introduction/motivation/#References","page":"Background and Motivation","title":"References","text":"","category":"section"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"[STEINWART2008]: Steinwart, Ingo, and Andreas Christmann. \"Support vector machines\". Springer Science & Business Media, 2008.","category":"page"},{"location":"introduction/motivation/","page":"Background and Motivation","title":"Background and Motivation","text":"[SHALEV2014]: Shalev-Shwartz, Shai, and Shai Ben-David. \"Understanding machine learning: From theory to algorithms\". Cambridge University Press, 2014.","category":"page"},{"location":"user/interface/","page":"Working with Losses","title":"Working with Losses","text":"DocTestSetup = quote\n    using LossFunctions\nend","category":"page"},{"location":"user/interface/#Working-with-Losses","page":"Working with Losses","title":"Working with Losses","text":"","category":"section"},{"location":"user/interface/","page":"Working with Losses","title":"Working with Losses","text":"Even though they are called loss \"functions\", this package implements them as immutable types instead of true Julia functions. There are good reasons for that. For example it allows us to specify the properties of loss functions explicitly (e.g. isconvex(myloss)). It also makes for a more consistent API when it comes to computing the value or the derivative. Some loss functions even have additional parameters that need to be specified, such as the epsilon in the case of the epsilon-insensitive loss. Here, types allow for member variables to hide that information away from the method signatures.","category":"page"},{"location":"user/interface/","page":"Working with Losses","title":"Working with Losses","text":"In order to avoid potential confusions with true Julia functions, we will refer to \"loss functions\" as \"losses\" instead. The available losses share a common interface for the most part. This section will provide an overview of the basic functionality that is available for all the different types of losses. We will discuss how to create a loss, how to compute its value and derivative, and how to query its properties.","category":"page"},{"location":"user/interface/#Instantiating-a-Loss","page":"Working with Losses","title":"Instantiating a Loss","text":"","category":"section"},{"location":"user/interface/","page":"Working with Losses","title":"Working with Losses","text":"Losses are immutable types. As such, one has to instantiate one in order to work with it. For most losses, the constructors do not expect any parameters.","category":"page"},{"location":"user/interface/","page":"Working with Losses","title":"Working with Losses","text":"julia> L2DistLoss()\nL2DistLoss()\n\njulia> HingeLoss()\nL1HingeLoss()","category":"page"},{"location":"user/interface/","page":"Working with Losses","title":"Working with Losses","text":"We just said that we need to instantiate a loss in order to work with it. One could be inclined to belief, that it would be more memory-efficient to \"pre-allocate\" a loss when using it in more than one place.","category":"page"},{"location":"user/interface/","page":"Working with Losses","title":"Working with Losses","text":"julia> loss = L2DistLoss()\nL2DistLoss()\n\njulia> loss(3, 2)\n1","category":"page"},{"location":"user/interface/","page":"Working with Losses","title":"Working with Losses","text":"However, that is a common oversimplification. Because all losses are immutable types, they can live on the stack and thus do not come with a heap-allocation overhead.","category":"page"},{"location":"user/interface/","page":"Working with Losses","title":"Working with Losses","text":"Even more interesting in the example above, is that for such losses as L2DistLoss, which do not have any constructor parameters or member variables, there is no additional code executed at all. Such singletons are only used for dispatch and don't even produce any additional code, which you can observe for yourself in the code below. As such they are zero-cost abstractions.","category":"page"},{"location":"user/interface/","page":"Working with Losses","title":"Working with Losses","text":"julia> v1(loss,y,t) = loss(y,t)\n\njulia> v2(y,t) = L2DistLoss()(y,t)\n\njulia> @code_llvm v1(loss, 3, 2)\ndefine i64 @julia_v1_70944(i64, i64) #0 {\ntop:\n  %2 = sub i64 %1, %0\n  %3 = mul i64 %2, %2\n  ret i64 %3\n}\n\njulia> @code_llvm v2(3, 2)\ndefine i64 @julia_v2_70949(i64, i64) #0 {\ntop:\n  %2 = sub i64 %1, %0\n  %3 = mul i64 %2, %2\n  ret i64 %3\n}","category":"page"},{"location":"user/interface/","page":"Working with Losses","title":"Working with Losses","text":"On the other hand, some types of losses are actually more comparable to whole families of losses instead of just a single one. For example, the immutable type L1EpsilonInsLoss has a free parameter epsilon. Each concrete epsilon results in a different concrete loss of the same family of epsilon-insensitive losses.","category":"page"},{"location":"user/interface/","page":"Working with Losses","title":"Working with Losses","text":"julia> L1EpsilonInsLoss(0.5)\nL1EpsilonInsLoss{Float64}(0.5)\n\njulia> L1EpsilonInsLoss(1)\nL1EpsilonInsLoss{Float64}(1.0)","category":"page"},{"location":"user/interface/","page":"Working with Losses","title":"Working with Losses","text":"For such losses that do have parameters, it can make a slight difference to pre-instantiate a loss. While they will live on the stack, the constructor usually performs some assertions and conversion for the given parameter. This can come at a slight overhead. At the very least it will not produce the same exact code when pre-instantiated. Still, the fact that they are immutable makes them very efficient abstractions with little to no performance overhead, and zero memory allocations on the heap.","category":"page"},{"location":"user/interface/#Computing-the-Values","page":"Working with Losses","title":"Computing the Values","text":"","category":"section"},{"location":"user/interface/","page":"Working with Losses","title":"Working with Losses","text":"The first thing we may want to do is compute the loss for some observation (singular). In fact, all losses are implemented on single observations under the hood, and are functors.","category":"page"},{"location":"user/interface/","page":"Working with Losses","title":"Working with Losses","text":"julia> loss = L1DistLoss()\nL1DistLoss()\n\njulia> loss.([2,5,-2], [1,2,3])\n3-element Vector{Int64}:\n 1\n 3\n 5","category":"page"},{"location":"user/interface/#Computing-the-1st-Derivatives","page":"Working with Losses","title":"Computing the 1st Derivatives","text":"","category":"section"},{"location":"user/interface/","page":"Working with Losses","title":"Working with Losses","text":"Maybe the more interesting aspect of loss functions are their derivatives. In fact, most of the popular learning algorithm in Supervised Learning, such as gradient descent, utilize the derivatives of the loss in one way or the other during the training process.","category":"page"},{"location":"user/interface/","page":"Working with Losses","title":"Working with Losses","text":"To compute the derivative of some loss we expose the function deriv. It may be interesting to note explicitly, that we always compute the derivative in respect to the predicted output, since we are interested in deducing in which direction the output should change.","category":"page"},{"location":"user/interface/","page":"Working with Losses","title":"Working with Losses","text":"deriv","category":"page"},{"location":"user/interface/#LossFunctions.deriv","page":"Working with Losses","title":"LossFunctions.deriv","text":"deriv(loss, output, target) -> Number\n\nCompute the analytical derivative with respect to the output for the loss function. Note that target and output can be of different numeric type, in which case promotion is performed in the manner appropriate for the given loss.\n\n\n\n\n\n","category":"function"},{"location":"user/interface/#Computing-the-2nd-Derivatives","page":"Working with Losses","title":"Computing the 2nd Derivatives","text":"","category":"section"},{"location":"user/interface/","page":"Working with Losses","title":"Working with Losses","text":"Additionally to the first derivative, we also provide the corresponding methods for the second derivative through the function deriv2. Note again, that we always compute the derivative in respect to the predicted output.","category":"page"},{"location":"user/interface/","page":"Working with Losses","title":"Working with Losses","text":"deriv2","category":"page"},{"location":"user/interface/#LossFunctions.deriv2","page":"Working with Losses","title":"LossFunctions.deriv2","text":"deriv2(loss, output, target) -> Number\n\nCompute the second derivative with respect to the output for the loss function. Note that target and output can be of different numeric type, in which case promotion is performed in the manner appropriate for the given loss.\n\n\n\n\n\n","category":"function"},{"location":"user/interface/#Properties-of-a-Loss","page":"Working with Losses","title":"Properties of a Loss","text":"","category":"section"},{"location":"user/interface/","page":"Working with Losses","title":"Working with Losses","text":"In some situations it can be quite useful to assert certain properties about a loss-function. One such scenario could be when implementing an algorithm that requires the loss to be strictly convex or Lipschitz continuous. Note that we will only skim over the defintions in most cases. A good treatment of all of the concepts involved can be found in either [BOYD2004] or [STEINWART2008].","category":"page"},{"location":"user/interface/","page":"Working with Losses","title":"Working with Losses","text":"[BOYD2004]: Stephen Boyd and Lieven Vandenberghe. \"Convex Optimization\". Cambridge University Press, 2004.","category":"page"},{"location":"user/interface/","page":"Working with Losses","title":"Working with Losses","text":"[STEINWART2008]: Steinwart, Ingo, and Andreas Christmann. \"Support vector machines\". Springer Science & Business Media, 2008.","category":"page"},{"location":"user/interface/","page":"Working with Losses","title":"Working with Losses","text":"This package uses functions to represent individual properties of a loss. It follows a list of implemented property-functions defined in LearnBase.jl.","category":"page"},{"location":"user/interface/","page":"Working with Losses","title":"Working with Losses","text":"isconvex\nisstrictlyconvex\nisstronglyconvex\nisdifferentiable\nistwicedifferentiable\nislocallylipschitzcont\nislipschitzcont\nisnemitski\nisclipable\nismarginbased\nisclasscalibrated\nisdistancebased\nissymmetric","category":"page"},{"location":"user/interface/#LossFunctions.isconvex","page":"Working with Losses","title":"LossFunctions.isconvex","text":"isconvex(loss) -> Bool\n\nReturn true if the given loss denotes a convex function. A function f: ℝⁿ → ℝ is convex if its domain is a convex set and if for all x, y in that domain, with θ such that for 0 ≦ θ ≦ 1, we have f(θ x + (1 - θ) y) ≦ θ f(x) + (1 - θ) f(y).\n\n\n\n\n\n","category":"function"},{"location":"user/interface/#LossFunctions.isstrictlyconvex","page":"Working with Losses","title":"LossFunctions.isstrictlyconvex","text":"isstrictlyconvex(loss) -> Bool\n\nReturn true if the given loss denotes a strictly convex function. A function f : ℝⁿ → ℝ is strictly convex if its domain is a convex set and if for all x, y in that domain where x ≠ y, with θ such that for 0 < θ < 1, we have f(θ x + (1 - θ) y) < θ f(x) + (1 - θ) f(y).\n\n\n\n\n\n","category":"function"},{"location":"user/interface/#LossFunctions.isstronglyconvex","page":"Working with Losses","title":"LossFunctions.isstronglyconvex","text":"isstronglyconvex(loss) -> Bool\n\nReturn true if the given loss denotes a strongly convex function. A function f : ℝⁿ → ℝ is m-strongly convex if its domain is a convex set, and if for all x, y in that domain where x ≠ y, and θ such that for 0 ≤ θ ≤ 1, we have f(θ x + (1 - θ)y) < θ f(x) + (1 - θ) f(y) - 0.5 m ⋅ θ (1 - θ) | x - y |₂²\n\nIn a more familiar setting, if the loss function is differentiable we have (∇f(x) - ∇f(y))ᵀ (x - y) ≥ m | x - y |₂²\n\n\n\n\n\n","category":"function"},{"location":"user/interface/#LossFunctions.isdifferentiable","page":"Working with Losses","title":"LossFunctions.isdifferentiable","text":"isdifferentiable(loss, [x]) -> Bool\n\nReturn true if the given loss is differentiable (optionally limited to the given point x if specified).\n\nA function f : ℝⁿ → ℝᵐ is differentiable at a point x in the interior domain of f if there exists a matrix Df(x) ∈ ℝ^(m × n) such that it satisfies:\n\nlim_{z ≠ x, z → x} (|f(z) - f(x) - Df(x)(z-x)|₂) / |z - x|₂ = 0\n\nA function is differentiable if its domain is open and it is differentiable at every point x.\n\n\n\n\n\n","category":"function"},{"location":"user/interface/#LossFunctions.istwicedifferentiable","page":"Working with Losses","title":"LossFunctions.istwicedifferentiable","text":"istwicedifferentiable(loss, [x]) -> Bool\n\nReturn true if the given loss is differentiable (optionally limited to the given point x if specified).\n\nA function f : ℝⁿ → ℝ is said to be twice differentiable at a point x in the interior domain of f, if the function derivative for ∇f exists at x: ∇²f(x) = D∇f(x).\n\nA function is twice differentiable if its domain is open and it is twice differentiable at every point x.\n\n\n\n\n\n","category":"function"},{"location":"user/interface/#LossFunctions.islocallylipschitzcont","page":"Working with Losses","title":"LossFunctions.islocallylipschitzcont","text":"islocallylipschitzcont(loss) -> Bool\n\nReturn true if the given loss function is locally-Lipschitz continous.\n\nA supervised loss L : Y × ℝ → [0, ∞) is called locally Lipschitz continuous if for all a ≥ 0 there exists a constant cₐ ≥ 0, such that\n\nsup_{y ∈ Y} | L(y,t) − L(y,t′) | ≤ cₐ |t − t′|, t, t′ ∈ [−a,a]\n\nEvery convex function is locally lipschitz continuous.\n\n\n\n\n\n","category":"function"},{"location":"user/interface/#LossFunctions.islipschitzcont","page":"Working with Losses","title":"LossFunctions.islipschitzcont","text":"islipschitzcont(loss) -> Bool\n\nReturn true if the given loss function is Lipschitz continuous.\n\nA supervised loss function L : Y × ℝ → [0, ∞) is Lipschitz continous, if there exists a finite constant M < ∞ such that |L(y, t) - L(y, t′)| ≤ M |t - t′|, ∀ (y, t) ∈ Y × ℝ\n\n\n\n\n\n","category":"function"},{"location":"user/interface/#LossFunctions.isnemitski","page":"Working with Losses","title":"LossFunctions.isnemitski","text":"isnemitski(loss) -> Bool\n\nReturn true if the given loss denotes a Nemitski loss function.\n\nWe call a supervised loss function L : Y × ℝ → [0,∞) a Nemitski loss if there exist a measurable function b : Y → [0, ∞) and an increasing function h : [0, ∞) → [0, ∞) such that L(y,ŷ) ≤ b(y) + h(|ŷ|), (y, ŷ) ∈ Y × ℝ\n\nIf a loss if locally lipsschitz continuous then it is a Nemitski loss.\n\n\n\n\n\n","category":"function"},{"location":"user/interface/#LossFunctions.isclipable","page":"Working with Losses","title":"LossFunctions.isclipable","text":"isclipable(loss) -> Bool\n\nReturn true if the given loss function is clipable. A supervised loss L : Y × ℝ → [0,∞) can be clipped at M > 0 if, for all (y,t) ∈ Y × ℝ, L(y, t̂) ≤ L(y, t) where t̂ denotes the clipped value of t at ± M. That is t̂ = -M if t < -M, t̂ = t if t ∈ [-M, M], and t = M if t > M.\n\n\n\n\n\n","category":"function"},{"location":"user/interface/#LossFunctions.ismarginbased","page":"Working with Losses","title":"LossFunctions.ismarginbased","text":"ismarginbased(loss) -> Bool\n\nReturn true if the given loss is a margin-based loss.\n\nA supervised loss function L : Y × ℝ → [0,∞) is said to be margin-based, if there exists a representing function ψ : ℝ → [0,∞) satisfying L(y, ŷ) = ψ(y⋅ŷ), (y, ŷ) ∈ Y × ℝ.\n\n\n\n\n\n","category":"function"},{"location":"user/interface/#LossFunctions.isclasscalibrated","page":"Working with Losses","title":"LossFunctions.isclasscalibrated","text":"isclasscalibrated(loss) -> Bool\n\n\n\n\n\n","category":"function"},{"location":"user/interface/#LossFunctions.isdistancebased","page":"Working with Losses","title":"LossFunctions.isdistancebased","text":"isdistancebased(loss) -> Bool\n\nReturn true if the given loss is a distance-based loss.\n\nA supervised loss function L : Y × ℝ → [0,∞) is said to be distance-based, if there exists a representing function ψ : ℝ → [0,∞) satisfying ψ(0) = 0 and L(y, ŷ) = ψ (ŷ - y), (y, ŷ) ∈ Y × ℝ.\n\n\n\n\n\n","category":"function"},{"location":"user/interface/#LossFunctions.issymmetric","page":"Working with Losses","title":"LossFunctions.issymmetric","text":"issymmetric(loss) -> Bool\n\nReturn true if the given loss is a symmetric loss.\n\nA function f : ℝ → [0,∞) is said to be symmetric about origin if we have f(x) = f(-x), ∀ x ∈ ℝ.\n\nA distance-based loss is said to be symmetric if its representing function is symmetric.\n\n\n\n\n\n","category":"function"},{"location":"LICENSE/#LICENSE","page":"LICENSE","title":"LICENSE","text":"","category":"section"},{"location":"LICENSE/","page":"LICENSE","title":"LICENSE","text":"using Markdown\nMarkdown.parse_file(joinpath(@__DIR__, \"..\", \"..\", \"LICENSE.md\"))","category":"page"},{"location":"#LossFunctions.jl's-documentation","page":"Home","title":"LossFunctions.jl's documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package represents a community effort to centralize the definition and implementation of loss functions in Julia. As such, it is a part of the JuliaML ecosystem.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The sole purpose of this package is to provide an efficient and extensible implementation of various loss functions used throughout Machine Learning (ML). It is thus intended to serve as a special purpose back-end for other ML libraries that require losses to accomplish their tasks. To that end we provide a considerable amount of carefully implemented loss functions, as well as an API to query their properties (e.g. convexity). Furthermore, we expose methods to compute their values, derivatives, and second derivatives for single observations as well as arbitrarily sized arrays of observations. In the case of arrays a user additionally has the ability to define if and how element-wise results are averaged or summed over.","category":"page"},{"location":"","page":"Home","title":"Home","text":"From an end-user's perspective one normally does not need to import this package directly. That said, it should provide a decent starting point for any student that is interested in investigating the properties or behaviour of loss functions.","category":"page"},{"location":"#Introduction-and-Motivation","page":"Home","title":"Introduction and Motivation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If this is the first time you consider using LossFunctions for your machine learning related experiments or packages, make sure to check out the \"Getting Started\" section.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"introduction/gettingstarted.md\"]\nDepth = 2","category":"page"},{"location":"","page":"Home","title":"Home","text":"If you are new to Machine Learning in Julia, or are simply interested in how and why this package works the way it works, feel free to take a look at the following sections. There we discuss the concepts involved and outline the most important terms and definitions.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"introduction/motivation.md\"]\nDepth = 2","category":"page"},{"location":"#User's-Guide","page":"Home","title":"User's Guide","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This section gives a more detailed treatment of the exposed functions and their available methods. We will start by describing how to instantiate a loss, as well as the basic interface that all loss functions share.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"user/interface.md\"]\nDepth = 2","category":"page"},{"location":"","page":"Home","title":"Home","text":"Next we will consider how to average or sum the results of the loss functions more efficiently. The methods described here are implemented in such a way as to avoid allocating a temporary array.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"user/aggregate.md\"]\nDepth = 2","category":"page"},{"location":"#Available-Losses","page":"Home","title":"Available Losses","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Aside from the interface, this package also provides a number of popular (and not so popular) loss functions out-of-the-box. Great effort has been put into ensuring a correct, efficient, and type-stable implementation for those. Most of them either belong to the family of distance-based or margin-based losses. These two categories are also indicative for if a loss is intended for regression or classification problems","category":"page"},{"location":"#Loss-Functions-for-Regression","page":"Home","title":"Loss Functions for Regression","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Loss functions that belong to the category \"distance-based\" are primarily used in regression problems. They utilize the numeric difference between the predicted output and the true target as a proxy variable to quantify the quality of individual predictions.","category":"page"},{"location":"","page":"Home","title":"Home","text":"<table><tbody><tr><td style=\"text-align: left;\">","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"losses/distance.md\"]\nDepth = 2","category":"page"},{"location":"","page":"Home","title":"Home","text":"</td><td>","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: distance-based losses)","category":"page"},{"location":"","page":"Home","title":"Home","text":"</td></tr></tbody></table>","category":"page"},{"location":"#Loss-Functions-for-Classification","page":"Home","title":"Loss Functions for Classification","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Margin-based loss functions are particularly useful for binary classification. In contrast to the distance-based losses, these do not care about the difference between true target and prediction. Instead they penalize predictions based on how well they agree with the sign of the target.","category":"page"},{"location":"","page":"Home","title":"Home","text":"<table><tbody><tr><td style=\"text-align: left;\">","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"losses/margin.md\"]\nDepth = 2","category":"page"},{"location":"","page":"Home","title":"Home","text":"</td><td>","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: margin-based losses)","category":"page"},{"location":"","page":"Home","title":"Home","text":"</td></tr></tbody></table>","category":"page"},{"location":"#Advanced-Topics","page":"Home","title":"Advanced Topics","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"In some situations it can be useful to slightly alter an existing loss function. We provide two general ways to accomplish that. The first way is to scale a loss by a constant factor. This can for example be useful to transform the L2DistLoss into the least squares loss one knows from statistics. The second way is to reweight the two classes of a binary classification loss. This is useful for handling inbalanced class distributions.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"advanced/extend.md\"]\nDepth = 2","category":"page"},{"location":"","page":"Home","title":"Home","text":"If you are interested in contributing to LossFunctions.jl, or simply want to understand how and why the package does then take a look at our developer documentation (although it is a bit sparse at the moment).","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"advanced/developer.md\"]\nDepth = 2","category":"page"},{"location":"#Index","page":"Home","title":"Index","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"indices.md\"]","category":"page"}]
}
